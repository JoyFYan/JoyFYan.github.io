<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[from wordpress to hexo 搬迁成功]]></title>
      <url>%2F2016%2F11%2F18%2Ffrom-wordpress-to-hexo-%E6%90%AC%E8%BF%81%E6%88%90%E5%8A%9F%2F</url>
      <content type="text"><![CDATA[搬迁成功！之前网站建立在树莓派服务器上，很大的问题在于没有固定的IP，经常找不到服务器。。 经过一段时间的探索，发现github.io真是建站神器，免费的空间还没有什么限制。唯一一点可能是在PKU更新内网无法访问……这也导致一开始的尝试一直处于失败状态。（另外git clone coding也失败，这个不是内网吗？） 注意的问题当然在部署时还是有一定的问题出现： Deployer not found 当键入hexo d时会出现 1RROR Deployer not found: 这是因为git的部署器没有安装，需要安装后： 1npm install hexo-deployer-git --save 再执行。 当然遗憾的是还是出错： 123456789101112131415 NFO Deploying: gitINFO Setting up Git deployment...'git' FATAL Something's wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlError: spawn git ENOENT at notFoundError (F:\myhexo\node_modules\cross-spawn\lib\enoent.js:11:11) at verifyENOENT (F:\myhexo\node_modules\cross-spawn\lib\enoent.js:46:16) at ChildProcess.cp.emit (F:\myhexo\node_modules\cross-spawn\lib \enoent.js:33:19) at Process.ChildProcess._handle.onexit (internal/child_process.js:215:12)FATAL spawn git ENOENTError: spawn git ENOENT at notFoundError (F:\myhexo\node_modules\cross-spawn\lib\enoent.js:11:11) at verifyENOENT (F:\myhexo\node_modules\cross-spawn\lib\enoent.js:46:16) at ChildProcess.cp.emit (F:\myhexo\node_modules\cross-spawn\lib \enoent.js:33:19) at Process.ChildProcess._handle.onexit (internal/child_process.js:215:12) 跟当初wordpress一样总会留个问题啊。。 注意站点设置文件与主题设置文件的区别 这个在Next的设置中其实也有提示，然而我并没有很注意= =||一开始多说的评论设置在站点设置文件更改没有问题，但菜单始终失败，最后发现是应该在主题设置文件更改。 下一步之前wordpress的文章基本上都迁移过来了，但是图片就比较麻烦了，需要重新整理，抽空弄一下吧。Hexo生成的是静态网页，有一点不好是非常依赖hexo程序的生成，这样就不能随时随地发了（当是发微博吗？）……总之小站重新复活，好好干~ 感谢Hexo，感谢Next主题对本博客的大力支持。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Caffe-faster-rcnn demo测试]]></title>
      <url>%2F2016%2F11%2F12%2FCaffe-faster-rcnn%20demo%E6%B5%8B%E8%AF%95%2F</url>
      <content type="text"><![CDATA[RCNN是目前detection中较新且准确度较高的方法，充分发挥了CNN分类的优势，但速度并不快，从而产生了fast rcnn和faster rcnn来解决这个问题。本文使用py-faster-rcnn对该方法做一初步测试。 rbgirshick/py-faster-rcnn 环境准备软件环境 Caffe Python 一般来说这些我们都已经有所接触，但仍有一些需要注意的地方： 要使用rbgirshick/py-faster-rcnn中的caffe编译一次，其caffe在rbgirshick/py-faster-rcnn/caffe-fast-rcnn @ 0dcd397中。因为这里面有一些专门为f-rcnn写的层，具体区别可以在caffe.proto中查看，如增加了ROIPoolingParameter、SmoothL1LossParameter等参数。 编译时一定要增加对Python层（Python layers）的支持。具体需要打开Makefile.config，找到： 12# In your Makefile.config, make sure to have this line uncommentedWITH_PYTHON_LAYER := 1 将其改为1，否则运行时会出错，提示没有对应的layer。 硬件要求小的网络用Titan, K20, K40这些就可以，显存3G以上。大的可能需要K40,11G以上显存，当然这些往往个人无法搭建起来。 安装（DEMO） 编译Cython模块 12 cd $FRCN_ROOT/libmake $FRCN_ROOT为你的FRCNN根目录，下同。 编译Caffe 和 pycaffe 123456cd $FRCN_ROOT/caffe-fast-rcnn # Now follow the Caffe installation instructions here: # http://caffe.berkeleyvision.org/installation.html # If you&apos;re experienced with Caffe and have all of the requirements installed # and your Makefile.config in place, then simply do:make -j8 &amp;&amp; make pycaffe -j8是指8核编译，更快一些。 下载预计算的R-CNN检测器12cd $FRCN_ROOT./data/scripts/fetch_faster_rcnn_models.sh 这个模型解压出来750M，下载的话大概695M，而且很慢。。为了方便大家，我把模型上传到了百度云，faster_rcnn_models， 密码：gbpo。 运行这一步就很简单了，12cd $FRCN_ROOT./tools/demo.py 当然权限不足直接运行py也可以。这个运行是需要在图像界面下进行的，否则会报错。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caffe学习（11）python的数据可视化]]></title>
      <url>%2F2016%2F11%2F09%2Fcaffe%E5%AD%A6%E4%B9%A0%EF%BC%8811%EF%BC%89python%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
      <content type="text"><![CDATA[caffe本身没有可视化的工具，一般需要配合python或matlab实现数据的可视化，在实践本文之前要先把caffe python编译好。另外有的服务器只有shell，没有可视化的界面，只好先把每一层的数据先保存成图片格式，再进行显示。 Caffe学习系列(14)：初识数据可视化Python and/or MATLAB Caffe (optional) 载入数据12345678910import numpy as npimport caffefrom skimage import iocaffe_root='/home/XXX/caffe/'import os,sysos.chdir(caffe_root)sys.path.insert(0,caffe_root+'python')im = caffe.io.load_image('examples/images/cat.jpg')io.imsave('cat.jpg',im)print im.shape 这里用到了skimage 这个库，caffe用于读取图像的函数caffe.io.load_image也是用的这个，具体可以在python/caffe/io.py中查看。之后我们也用这个库进行图像的保存。以上的程序较为简单，读取了示例图片，为了验证是否正确又另存为了副本。最后输出的shape为：（360,480,3）。 载入卷积模型1net = caffe.Net('examples/net_surgery/conv.prototxt', caffe.TEST) 123456789101112131415161718192021222324252627# Simple single-layer network to showcase editing model parameters.name: "convolution"layer &#123; name: "data" type: "Input" top: "data" input_param &#123; shape: &#123; dim: 1 dim: 3 dim: 100 dim: 100 &#125; &#125;&#125;layer &#123; name: "conv" type: "Convolution" bottom: "data" top: "conv" convolution_param &#123; num_output: 16 kernel_size: 5 stride: 1 weight_filler &#123; type: "gaussian" std: 0.01 &#125; bias_filler &#123; type: "constant" value: 0 &#125; &#125;&#125; 载入的是示例中简单的卷积模型，但在shape上有所修改：第二个dim由1改为3，代表三通道输入；同时num_output改为了16，增加了滤波器的个数。 数据格式处理12345im_input=im[np.newaxis,:,:,:].transpose(0,3,1,2)print "data-blobs:",im_input.shape#print "datashape:",net.blobs['data'].data.shapenet.blobs['data'].reshape(*im_input.shape)net.blobs['data'].data[...] = im_input 图片的输入规格和caffe的blob规格并不相同。图片的维度为（360,480,3），而blob的4维数组要求通道数在前，因此需要改变顺序，并且由于仅有一张图片，需要增加一维代表图片序号，该维值为0即可。因此im_input=im[np.newaxis,:,:,:].transpose(0,3,1,2)先增加了一个维度，后改变了维的顺序，使其与输入要求相同。之后改变blobs数据层的维度，使之与图像大小相同（这一步感觉会让网络配置文件中input_param：shape的维度改变，可能是为了方便程序的扩展，没有直接改配置文件）。最后把图像数据输入到blob。 保存图像为了方便调用，可以写一个保存图片的函数：1234567891011def save_data(data,name,padsize=1, padval=0): data -= data.min() data /= data.max() # force the number of filters to be square n = int(np.ceil(np.sqrt(data.shape[0]))) padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3) data = np.pad(data, padding, mode='constant', constant_values=(padval, padval)) # tile the filters into an image data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1))) data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:]) io.imsave(name,data) 保存图片首先进行了归一化操作，之后为了美观生成一个方形模板，再把图片依次放上去。测试这一段可以看一下原图多通道的每一通道分量：1save_data(net.blobs['data'].data[0],'origin images.jpg') 卷积层输出123456net.forward()print "data-blobs:",net.blobs['data'].data.shapeprint "conv-blobs:",net.blobs['conv'].data.shapeprint "weight-blobs:",net.params['conv'][0].data.shapesave_data(net.params['conv'][0].data[:,0],'conv weights(filter).jpg')save_data(net.blobs['conv'].data[0],'post-conv images.jpg') 经过一次向前计算，得到了卷积后的结果和初始的卷积核值，打印他们的大小分别为： data-blobs: (1, 3, 360, 480) conv-blobs: (1, 16, 356, 476) weight-blobs: (16, 3, 5, 5) 最后保存成了两个图片文件：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caffe学习（10）数据转换img2db]]></title>
      <url>%2F2016%2F11%2F08%2Fcaffe%E5%AD%A6%E4%B9%A0%EF%BC%8810%EF%BC%89%E6%95%B0%E6%8D%AE%E8%BD%AC%E6%8D%A2img2db%2F</url>
      <content type="text"><![CDATA[在处理图像时，我们已拥有的图像往往是常用的jpg、png格式，但在caffe中，输入的数据类型常是lmdb或leveldb，因此我们需要对原始数据进行转换。 Caffe学习系列(11)：图像数据转换成db（leveldb/lmdb)文件 convert_imageset在caffe中，提供了一个用于格式转换的文件：convert_imageset.cpp，存放在根目录下的tools文件夹下。编译之后，生成对应的可执行文件放在 build/tools/ 下面，这个文件的作用就是用于将图片文件转换成caffe框架中能直接使用的db文件。而windows平台下，如果用vs编译会在build/x64/debug中生成convert_imageset.exe。 使用方法该文件的使用格式： convert_imageset [FLAGS] ROOTFOLDER/ LISTFILE DB_NAME 而数据集推荐的是imagenet。对于具体的参数包含有： FLAGS：图片转换参数。 ROOTFOLDER/：图片的绝对路径，从系统根目录开始。 LISTFILE：图片文件清单文件，为txt格式，一行有一张图片。 DB_NAME：生成db文件的存放目录。 其中图片文件清单比较麻烦，因此可以使用脚本文件读取图片并保存为txt。 图片文件清单的生成本文以caffe程序中自带的图片为例，进行讲解，图片目录是 example/images/, 两张图片，一张为cat.jpg, 另一张为fish_bike.jpg，表示两个类别。我们创建一个sh脚本文件，调用linux命令来生成图片清单： # sudo vi examples/images/create_filelist.sh 编辑这个文件,输入下面的代码并保存：123456789# /usr/bin/env shDATA=examples/imagesecho "Create train.txt..."rm -rf $DATA/train.txtfind $DATA -name *cat.jpg | cut -d '/' -f3 | sed "s/$/ 1/"&gt;&gt;$DATA/train.txtfind $DATA -name *bike.jpg | cut -d '/' -f3 | sed "s/$/ 2/"&gt;&gt;$DATA/tmp.txtcat $DATA/tmp.txt&gt;&gt;$DATA/train.txtrm -rf $DATA/tmp.txtecho "Done.." 这个脚本文件中，用到了rm,find, cut, sed,cat等linux命令。 rm: 删除文件 find: 寻找文件 cut: 截取路径 sed: 在每行的最后面加上标注。本例中将找到的cat.jpg文件加入标注为1，找到的bike.jpg文件加入标注为2 cat: 将两个类别合并在一个文件里。 最终生成如下的一个train.txt文件： cat.jpg 1 fish-bike.jpg 2 当然，图片很少的时候，手动编写这个列表清单文件就行了。但图片很多的情况，就需要用脚本文件来自动生成了。在以后的实际应用中，还需要生成相应的val.txt和test.txt文件，方法是一样的。生成的这个train.txt文件，就可以作为第三个参数，直接使用了。 FLAGS参数设置接下来，我们来了解一下FLAGS这个参数组，有些什么内容： gray: 是否以灰度图的方式打开图片。程序调用opencv库中的imread()函数来打开图片，默认为false shuffle: 是否随机打乱图片顺序。默认为false backend:需要转换成的db文件格式，可选为leveldb或lmdb,默认为lmdb resize_width/resize_height: 改变图片的大小。在运行中，要求所有图片的尺寸一致，因此需要改变图片大小。 程序调用opencv库的resize（）函数来对图片放大缩小，默认为0，不改变 check_size: 检查所有的数据是否有相同的尺寸。默认为false,不检查 encoded: 是否将原图片编码放入最终的数据中，默认为false encode_type: 与前一个参数对应，将图片编码为哪一个格式：‘png’,’jpg’…… 好了，知道这些参数后，我们就可以调用命令来生成最终的lmdb格式数据了。 转换脚本的编写由于参数比较多，因此我们可以编写一个sh脚本来执行命令。首先，创建sh脚本文件： # sudo vi examples/images/create_lmdb.sh 编辑，输入下面的代码并保存：123456#!/usr/bin/en shDATA=examples/imagesrm -rf $DATA/img_train_lmdbbuild/tools/convert_imageset --shuffle \--resize_height=256 --resize_width=256 \/home/xxx/caffe/examples/images/ $DATA/train.txt $DATA/img_train_lmdb 设置参数-shuffle,打乱图片顺序。设置参数-resize_height和-resize_width将所有图片尺寸都变为256*256。/home/xxx/caffe/examples/images/ 为图片保存的绝对路径。最后，运行这个脚本文件： # sudo sh examples/images/create_lmdb.sh 就会在examples/images/ 目录下生成一个名为 img_train_lmdb的文件夹，里面的文件就是我们需要的db文件了。 针对于windows环境，可以使用bat快速运行： D:/caffe-master/Build/x64/Release/convert_imageset --shuffle --resize_height=256 --resize_width=256 D:/caffe-master/examples/images/ D:/caffe-master/examples/images/train.txt D:/caffe-master/examples/images/img_train_lmdb]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caffe学习（9）LeNet在Caffe上的使用]]></title>
      <url>%2F2016%2F11%2F08%2Fcaffe%E5%AD%A6%E4%B9%A0%EF%BC%889%EF%BC%89LeNet%E5%9C%A8Caffe%E4%B8%8A%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[使用官网例程训练LeNet。 Training LeNet on MNIST with Caffe 准备数据Caffe程序的运行要注意需命令行要在Caffe的根目录下。 cd $CAFFE_ROOT ./data/mnist/get_mnist.sh ./examples/mnist/create_mnist.sh 依次运行，会在caffe\examples\mnist下得到两个目录mnist_train_lmdb, 和 mnist_test_lmdb，作为训练和测试集。 定义MNIST网络Caffe上的LeNet并不是传统的LeNet-5，在参数上还是有所不同的。以\caffe\examples\mnist\lenet_train_test.prototxt 为例（本地文件与官网上的教程也有所区别），介绍一下如何定义网络。首先是定义网络名称：1name: "LeNet" 数据层利用我们已经生成的MNIST数据，把数据输入到网络：12345678910111213141516171819202122232425262728293031323334layer &#123; name: "mnist" type: "Data" top: "data" top: "label" include &#123; phase: TRAIN &#125; transform_param &#123; scale: 0.00390625 &#125; data_param &#123; source: "examples/mnist/mnist_train_lmdb" batch_size: 64 backend: LMDB &#125;&#125;layer &#123; name: "mnist" type: "Data" top: "data" top: "label" include &#123; phase: TEST &#125; transform_param &#123; scale: 0.00390625 &#125; data_param &#123; source: "examples/mnist/mnist_test_lmdb" batch_size: 100 backend: LMDB &#125;&#125; 具体来说，本层名为：”mnist”，类型为”data”，输出到两个blob：”data””label”。下面用到了之前所说的include，包含TRAIN与TEST，表示该层是在训练还是测试时调用，其区别在于输入的不同数据集（见data_param）。transform_param用于输入数据的缩放，使之在$[0,1]$内，其中$0.00390625=1/256$。 卷积层本网络中，有两个卷积层，第一层为：1234567891011121314151617181920212223layer &#123; name: "conv1" type: "Convolution" bottom: "data" top: "conv1" param &#123; lr_mult: 1 &#125; param &#123; lr_mult: 2 &#125; convolution_param &#123; num_output: 20 kernel_size: 5 stride: 1 weight_filler &#123; type: "xavier" &#125; bias_filler &#123; type: "constant" &#125; &#125;&#125; 这一层使用数据层的数据作为输入，生成”conv1”层，具体产生20个通道的输出，卷积核大小为5，卷积步长为1。先后两个lr_mults是对本层可学习参数的速率调整，权重学习率与solver中的学习率相同，而偏置学习率为其两倍，这往往导致更好的手链率。权重初始化使用”xavier”方式，偏置初始化为0。第二个卷积层在池化层1后，输出到池化层2，参数除了输出个数（num_output）改为50，其余的相同。 池化层1234567891011layer &#123; name: "pool1" type: "Pooling" bottom: "conv1" top: "pool1" pooling_param &#123; pool: MAX kernel_size: 2 stride: 2 &#125;&#125; 第一个池化层表示采用最大池化的方法，进行大小为2，步长为2的非重叠池化。第二个池化层与第一个完全相同，其输入为卷积层2，输出到全连接层1. 全连接层123456789101112131415161718192021layer &#123; name: "ip1" type: "InnerProduct" bottom: "pool2" top: "ip1" param &#123; lr_mult: 1 &#125; param &#123; lr_mult: 2 &#125; inner_product_param &#123; num_output: 500 weight_filler &#123; type: "xavier" &#125; bias_filler &#123; type: "constant" &#125; &#125;&#125; 全连接层与卷积层的写法非常相似，ip1层产生500个输出。在激活层后，还有一个全连接层，用于最后的输出分类，因此有10个输出。 激活层123456layer &#123; name: "relu1" type: "ReLU" bottom: "ip1" top: "ip1"&#125; ReLU是一个元素操作，因此可以使用原地操作（in-place operations）用于节省空间。其实就是top与bottom的名字相同。当然其他的层不能使用重复的blob名称。 损失层最后是损失层：1234567layer &#123; name: "loss" type: "SoftmaxWithLoss" bottom: "ip2" bottom: "label" top: "loss"&#125; softmax_loss层同时实现softmax和多项对数损失（这可以节省时间并提高数值稳定性）。输入为预测的输出和label，并且没有输出（向后的输出）。它计算损失函数，并且反向传播相对于ip2的梯度。 Accuracy准确率层这一层是用于在测试中返回准确率使用的：12345678910layer &#123; name: "accuracy" type: "Accuracy" bottom: "ip2" bottom: "label" top: "accuracy" include &#123; phase: TEST &#125;&#125; 与loss相似，但要注明phase: TEST。 定义MNIST 求解器求解器文件路径为： $CAFFE_ROOT/examples/mnist/lenet_solver.prototxt: 12345678910111213141516171819202122232425# The train/test net protocol buffer definitionnet: "examples/mnist/lenet_train_test.prototxt"# test_iter specifies how many forward passes the test should carry out.# In the case of MNIST, we have test batch size 100 and 100 test iterations,# covering the full 10,000 testing images.test_iter: 100# Carry out testing every 500 training iterations.test_interval: 500# The base learning rate, momentum and the weight decay of the network.base_lr: 0.01momentum: 0.9weight_decay: 0.0005# The learning rate policylr_policy: "inv"gamma: 0.0001power: 0.75# Display every 100 iterationsdisplay: 100# The maximum number of iterationsmax_iter: 10000# snapshot intermediate resultssnapshot: 5000snapshot_prefix: "examples/mnist/lenet"# solver mode: CPU or GPUsolver_mode: GPU 这些参数见上一篇：caffe学习（8）Solver 配置详解。 训练并测试模型简单的话可以直接运行： cd $CAFFE_ROOT ./examples/mnist/train_lenet.sh 即运行： ./build/tools/caffe train --solver=examples/mnist/lenet_solver.prototxt 也就是我们上面的求解器配置文件。首先出现的是我们打开的solver文件，之后打开网络模型：lenet_train_test.prototxt，初始化网络参数。 I1108 16:08:29.103813 46285 layer_factory.hpp:77] Creating layer mnist I1108 16:08:29.104310 46285 net.cpp:100] Creating Layer mnist I1108 16:08:29.104336 46285 net.cpp:408] mnist -&gt; data I1108 16:08:29.104374 46285 net.cpp:408] mnist -&gt; label I1108 16:08:29.107558 46328 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb 不过仔细看的话会发现初始化了两遍网络，其实是因为我们同时在训练和测试，这两个网络的区别就是测试有”accuracy”层，训练没有。这些信息告诉了层之间的连接、输入、输出关系。结束后正式开始训练： I1108 16:08:29.156116 46285 net.cpp:283] Network initialization done. I1108 16:08:29.156206 46285 solver.cpp:60] Solver scaffolding done. I1108 16:08:29.156466 46285 caffe.cpp:251] Starting Optimization I1108 16:08:29.156500 46285 solver.cpp:279] Solving LeNet I1108 16:08:29.156512 46285 solver.cpp:280] Learning Rate Policy: inv I1108 16:08:29.158172 46285 solver.cpp:337] Iteration 0, Testing net (#0) I1108 16:08:31.021287 46285 solver.cpp:404] Test net output #0: accuracy = 0.0933 I1108 16:08:31.021385 46285 solver.cpp:404] Test net output #1: loss = 2.36349 (* 1 = 2.36349 loss) 可以看到，初始化参数后测试模型，准确率有9.33%，比10%还低一些。基于参数设置，我们每迭代100次输出loss 信息，每迭代500次测试模型，输出accuracy 信息： I1108 16:08:46.974346 46285 solver.cpp:337] Iteration 500, Testing net (#0) I1108 16:08:48.808943 46285 solver.cpp:404] Test net output #0: accuracy = 0.9767 I1108 16:08:48.809048 46285 solver.cpp:404] Test net output #1: loss = 0.068445 (* 1 = 0.068445 loss) I1108 16:08:48.823623 46285 solver.cpp:228] Iteration 500, loss = 0.0609579 I1108 16:08:48.823714 46285 solver.cpp:244] Train net output #0: loss = 0.0609579 (* 1 = 0.0609579 loss) I1108 16:08:48.823740 46285 sgd_solver.cpp:106] Iteration 500, lr = 0.0192814 可以发现输出500次后准确率已经达到了97.67%。达到训练次数后（这里减少了训练次数），得到最终结果： I1108 16:09:04.727638 46285 solver.cpp:454] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel I1108 16:09:04.754024 46285 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate I1108 16:09:04.770093 46285 solver.cpp:317] Iteration 1000, loss = 0.0819535 I1108 16:09:04.770177 46285 solver.cpp:337] Iteration 1000, Testing net (#0) I1108 16:09:06.607952 46285 solver.cpp:404] Test net output #0: accuracy = 0.9844 I1108 16:09:06.608042 46285 solver.cpp:404] Test net output #1: loss = 0.0491373 (* 1 = 0.0491373 loss) I1108 16:09:06.608055 46285 solver.cpp:322] Optimization Done. I1108 16:09:06.608064 46285 caffe.cpp:254] Optimization Done. 得到了两个文件：lenet_iter_1000.caffemodel和lenet_iter_1000.solverstate。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caffe学习（8）Solver 配置详解]]></title>
      <url>%2F2016%2F11%2F08%2Fcaffe%E5%AD%A6%E4%B9%A0%EF%BC%888%EF%BC%89Solver%20%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[Solver是求解学习模型的核心配置文件，网络确定后，solver就决定了学习的效果。本文结合caffe.proto和网上资料，对solver配置进行学习。 SolverCaffe学习系列(7)：solver及其配置，denny402 Solver在caffe中的定义通常的solver文件与net文件相互关联，同样的net我们往往使用不同的solver尝试得到最好的效果，其运行代码为： caffe train --solver=*_slover.prototxt 关于solver的一切，都在caffe.proto文件中message SolverParameter 这一部分。 网络文件源12345678910// Proto filename for the train net, possibly combined with one or more// test nets.optional string net = 24;// Inline train net param, possibly combined with one or more test nets.optional NetParameter net_param = 25;optional string train_net = 1; // Proto filename for the train net.repeated string test_net = 2; // Proto filenames for the test nets.optional NetParameter train_net_param = 21; // Inline train net params.repeated NetParameter test_net_param = 22; // Inline test net params. 这是最开始的部分，需要说明net文件的位置。在这四个train_net_param, train_net, net_param, net字段中至少需要出现一个，当出现多个时，就会按着(1) test_net_param, (2) test_net, (3) net_param/net 的顺序依次求解。必须为每个test_net指定一个test_iter。还可以为每个test_net指定test_level和/或test_stage。注意的是：文件的路径要从caffe的根目录开始，其它的所有配置都是这样。可以看到这几行的标签序号并不是顺序的，也说明caffe在不断地修改，下一个可用的序号是41。 网络状态123456789// The states for the train/test nets. Must be unspecified or// specified once per net.//// By default, all states will have solver = true;// train_state will have phase = TRAIN,// and all test_state's will have phase = TEST.// Other defaults are set according to the NetState defaults.optional NetState train_state = 26;repeated NetState test_state = 27; 网络状态必须是未指定的或者只能在一个网络中指定一次。关于NetState，其定义为：123456789message NetState &#123; optional Phase phase = 1 [default = TEST]; optional int32 level = 2 [default = 0]; repeated string stage = 3;&#125;enum Phase &#123; TRAIN = 0; TEST = 1;&#125; 迭代器12// The number of iterations for each test net.repeated int32 test_iter = 3; 首先是test_iter，这需要与test layer中的batch_size结合起来理解。mnist数据中测试样本总数为10000，一次性执行全部数据效率很低，因此我们将测试数据分成几个批次来执行，每个批次的数量就是batch_size。假设我们设置batch_size为100，则需要迭代100次才能将10000个数据全部执行完。因此test_iter设置为100。执行完一次全部数据，称之为一个epoch。123456// The number of iterations between two testing phases.optional int32 test_interval = 4 [default = 0];optional bool test_compute_loss = 19 [default = false];// If true, run an initial test pass before the first iteration,// ensuring memory availability and printing the starting value of the loss.optional bool test_initialization = 32 [default = true]; test_interval是指测试间隔，每训练test_interval次，进行一次测试。同时test_compute_loss可以选择是否计算loss。test_initialization是指在第一次迭代前，计算初始的loss以确保内存可用。 123456789optional float base_lr = 5; // The base learning rate// the number of iterations between displaying info. If display = 0, no info// will be displayed.optional int32 display = 6;// Display the loss averaged over the last average_loss iterationsoptional int32 average_loss = 33 [default = 1];optional int32 max_iter = 7; // the maximum number of iterations// accumulate gradients over `iter_size` x `batch_size` instancesoptional int32 iter_size = 36 [default = 1]; base_lr指基础的学习率；display是信息显示间隔，迭代一定次数显示一次信息。average_loss用于显示在上次average_loss迭代中的平均损失。max_iter是最大迭代次数，需要合适设置达到精度、震荡的平衡。iter_size是迭代器大小，梯度的计算是通过iter_size x batch_size决定的。 学习策略 123456789101112optional string lr_policy = 8;optional float gamma = 9; // The parameter to compute the learning rate.optional float power = 10; // The parameter to compute the learning rate.optional float momentum = 11; // The momentum value.optional float weight_decay = 12; // The weight decay.// regularization types supported: L1 and L2// controlled by weight_decayoptional string regularization_type = 29 [default = "L2"];// the stepsize for learning rate policy "step"optional int32 stepsize = 13;// the stepsize for learning rate policy "multistep"repeated int32 stepvalue = 34; 只要是梯度下降法来求解优化，都会有一个学习率，也叫步长。base_lr用于设置基础学习率，在迭代的过程中，可以对基础学习率进行调整。怎么样进行调整，就是调整的策略，由lr_policy来设置。caffe提供了多种policy： fixed: 总是返回base_lr（学习率不变） step: 返回 base_lr * gamma ^ (floor(iter / step))还需要设置stepsize参数以确定step，iter表示当前迭代次数。 exp: 返回base_lr * gamma ^ iter， iter为当前迭代次数 inv: 如果设置为inv,还需要设置一个power, 返回base_lr (1 + gamma iter) ^ (- power) multistep: 如果设置为multistep,则还需要设置一个stepvalue。这个参数和step很相似，step是均匀等间隔变化，而multistep则是根据stepvalue值变化。 poly: 学习率进行多项式误差, 返回 base_lr (1 - iter/max_iter) ^ (power) sigmoid: 学习率进行sigmod衰减，返回 base_lr ( 1/(1 + exp(-gamma * (iter - stepsize))))。 multistep示例：1234567891011base_lr: 0.01momentum: 0.9weight_decay: 0.0005# The learning rate policylr_policy: "multistep"gamma: 0.9stepvalue: 5000stepvalue: 7000stepvalue: 8000stepvalue: 9000stepvalue: 9500 之后有momentum，上次梯度更新的权重；weight_decay权重衰减，防止过拟合；regularization_type正则化方式。 clip_gradients1optional float clip_gradients = 35 [default = -1]; 参数梯度的实际L2范数较大时，将clip_gradients设置为&gt; = 0，以将参数梯度剪切到该L2范数。具体作用还不是很理解。 snapshot快照12345678910optional int32 snapshot = 14 [default = 0]; // The snapshot intervaloptional string snapshot_prefix = 15; // The prefix for the snapshot.// whether to snapshot diff in the results or not. Snapshotting diff will help// debugging but the final protocol buffer size will be much larger.optional bool snapshot_diff = 16 [default = false];enum SnapshotFormat &#123; HDF5 = 0; BINARYPROTO = 1;&#125;optional SnapshotFormat snapshot_format = 37 [default = BINARYPROTO]; 快照可以将训练出来的model和solver状态进行保存，snapshot用于设置训练多少次后进行保存，默认为0，不保存。snapshot_prefix设置保存路径。还可以设置snapshot_diff，是否保存梯度值，保存有利于调试，但需要较大空间存储，默认为false，不保存。也可以设置snapshot_format，保存的类型。有两种选择：HDF5 和BINARYPROTO ，默认为BINARYPROTO。 运行模式 1234567891011enum SolverMode &#123; CPU = 0; GPU = 1;&#125;optional SolverMode solver_mode = 17 [default = GPU];// the device_id will that be used in GPU mode. Use device_id = 0 in default.optional int32 device_id = 18 [default = 0];// If non-negative, the seed with which the Solver will initialize the Caffe// random number generator -- useful for reproducible results. Otherwise,// (and by default) initialize using a seed derived from the system clock.optional int64 random_seed = 20 [default = -1]; 设置CPU或GPU模式，在GPU下还可以指定使用哪一块GPU运行。random_seed用于初始生成随机数种子。 Solver类型 1234567891011// type of the solveroptional string type = 40 [default = "SGD"];// numerical stability for RMSProp, AdaGrad and AdaDelta and Adamoptional float delta = 31 [default = 1e-8];// parameters for the Adam solveroptional float momentum2 = 39 [default = 0.999];// RMSProp decay value// MeanSquare(t) = rms_decay*MeanSquare(t-1) + (1-rms_decay)*SquareGradient(t)optional float rms_decay = 38; type是solver的类型，目前有SGD、NESTEROV、ADAGRAD、RMSPROP、ADADELTA、ADAM = 5这六类。之后的一些是这些类型的特有参数，根据需要设置。 杂项 123456// If true, print information about the state of the net that may help with// debugging learning problems.optional bool debug_info = 23 [default = false];// If false, don't save a snapshot after training finishes.optional bool snapshot_after_train = 28 [default = true]; debug_info用于输出调试信息。snapshot_after_train用于训练后是否输出快照。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Google Protocol Buffer 学习]]></title>
      <url>%2F2016%2F11%2F07%2FGoogle%20Protocol%20Buffer%20%E5%AD%A6%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[Caffe上有很多使用了Google Protocol Buffer的东西，从网上来看，这“是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，很适合做数据存储或 RPC 数据交换格式。它可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式”。作为caffe模型定义的数据格式，看懂caffe.proto对caffe的理解会有很大帮助。 Google ProtobufGoogle Protocol Buffer 的使用和原理，刘 明 小例子我们首先要在.proto文件中定义协议缓冲区消息类型（protocol buffer message types），来指定要序列化的信息的结构。下面是官网的一个小例子，定义了一个人的信息： message Person { required string name = 1; required int32 id = 2; optional string email = 3; enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2; } message PhoneNumber { required string number = 1; optional PhoneType type = 2 [default = HOME]; } repeated PhoneNumber phone = 4; } 在 protobuf 的术语中，结构化数据被称为 Message，message中有不同成员。proto 文件非常类似 java 或者 C 语言的数据定义，string、int32这种类型我们已经见得多了。支持类型包括数字（整数或浮点）, 布尔值,，字符串，原始字节（raw bytes），或者是其他的message类型 (如上例) 。除了这些类型，其前后多了一些“修饰”。类型前是field rules，有可选（optional）、必填（required）、重复（repeated）三种。后面是message中的ID，同一message下ID随成员递增。 定义一个消息类型上面的例子其实已经定义了一个较为复杂的message。而对于一个完整的proto文件，在文件前还应该加上 syntax = &quot;proto2&quot;;//说明语法是2还是3 package caffe; //包名，通常与文件名相同 首先是field rules， Specifying Field Rules required：本字段一个massage必须只有一个。 optional：本字段可以有0个或1个。 repeated：本字段可以重复任何次，并保留顺序。 其中必填字段在使用中需要小心，特别是从必填改到可选时，读取时可能认为这个字段是不完整的。 Assigning Tags 定义消息中的每一个字段都有唯一的编号标签ID，用于消息二进制标识，并且在使用后不应该变。由于编码的原因，值在1到15范围的编号需要一个字节编码，包括标识号与字段类型。在16到2047范围的标签用两个字节。这对于数据储存大小有很大的联系，因此频繁出现的标签成员应该使编号尽可能小。其原因在于一种Varint的编码。其标签范围是1到$2^{29}-1$（536,870,911），同时除了中间的19000到19999，这是为协议缓冲区（Protocol Buffers）实现保留的。 Reserved Fields 保留字段，是对于被删除或者注释的字段进行保留， 如果以后加载相同.proto的旧版本，这可能会导致严重的问题。确保不会发生这种情况的一种方法是指定保留已删除字段的字段标签。协议缓冲区编译器将报告任何未来的用户是否尝试使用这些字段标识符。 message Foo { reserved 2, 15, 9 to 11; reserved &quot;foo&quot;, &quot;bar&quot;; } 不能在同一保留语句中混合字段名和标识号。 编译.proto文件使用写好的proto就可以用编译器将文件编译为目标语言了。在protobuf V3.0网站上可以下载 Protobuf V3.0的源代码，V2.6版本在网页上比较靠后，更新到2.6.1。然后解压编译安装便可以使用它了。从caffe文件上看用的还是2的语法。2和3的区别可以从网上搜到，如Google Protobuf 3版本介绍。其实变化也是不少，比如只保留repeated标记数组类型，optional和required都被去掉了；字段default标记不能使用了。 坑爹的是服务器没有权限装不了，于是只好在自家电脑上用windows版的。主要是用于验证， package lm; message helloworld { required int32 id = 1; // ID required string str = 2; // str optional int32 opt = 3; //optional field } 用命令行执行 protoc -I=. --cpp_out=. lm.helloworld.proto 得到了两个文件：lm.helloworld.pb.h ， 定义了 C++ 类的头文件lm.helloworld.pb.cc ， C++ 类的实现文件。有了这两个文件，之后我们想读写都可以用类操作实现了。 读写数据数据写到磁盘代码12345678910111213141516171819 #include "lm.helloworld.pb.h"… int main(void) &#123; lm::helloworld msg1; msg1.set_id(101); msg1.set_str(“hello”); // Write the new address book back to disk. fstream output("./log", ios::out | ios::trunc | ios::binary); if (!msg1.SerializeToOstream(&amp;output)) &#123; cerr &lt;&lt; "Failed to write msg." &lt;&lt; endl; return -1; &#125; return 0; &#125; 在代码中，其实重要的只是前三行，定义了helloworld类的对象，设置id的值，设置str的值。最后用SerializeToOstream输出到文件流。 读取数据代码 12345678910111213141516171819202122 #include "lm.helloworld.pb.h" … void ListMsg(const lm::helloworld &amp; msg) &#123; cout &lt;&lt; msg.id() &lt;&lt; endl; cout &lt;&lt; msg.str() &lt;&lt; endl; &#125; int main(int argc, char* argv[]) &#123; lm::helloworld msg1; &#123; fstream input("./log", ios::in | ios::binary); if (!msg1.ParseFromIstream(&amp;input)) &#123; cerr &lt;&lt; "Failed to parse address book." &lt;&lt; endl; return -1; &#125; &#125; ListMsg(msg1); … &#125; 在读取代码中，声明类 helloworld 的对象 msg1，然后利用 ParseFromIstream 从一个 fstream 流中读取信息并反序列化。此后，ListMsg 中采用 get 方法读取消息的内部信息，并进行打印输出操作。 分别运行后得到如下结果： &gt;writer &gt;reader 101 Hello 验证了程序。 Peotocol Buffer 编码在标签中说到了Varint，现在再结合编码讲一下，主要是参考了引用2的网页。Varint 中的每个 byte 的最高位 bit 有特殊的含义，如果该位为 1，表示后续的 byte 也是该数字的一部分，如果该位为 0，则结束。其他的 7 个 bit 都用来表示数字。因此小于 128 的数字都可以用一个 byte 表示。大于 128 的数字，比如 300，会用两个字节来表示：1010 1100 0000 0010。下图演示了 Google Protocol Buffer 如何解析两个 bytes。注意到最终计算前将两个 byte 的位置相互交换过一次，这是因为 Google Protocol Buffer 字节序采用 little-endian(小端在前) 的方式。消息经过序列化后会成为一个二进制数据流，该流中的数据为一系列的 Key-Value 对。如下图所示：采用这种 Key-Pair 结构无需使用分隔符来分割不同的 Field。对于可选的 Field，如果消息中不存在该 field，那么在最终的 Message Buffer 中就没有该 field，这些特性都有助于节约消息本身的大小。假如生成如下的消息： Test1.id = 10; Test1.str = “hello”； 则最终的 Message Buffer 中有两个 Key-Value 对，一个对应消息中的 id；另一个对应 str。Key 用来标识具体的 field，在解包的时候，Protocol Buffer 根据 Key 就可以知道相应的 Value 应该对应于消息中的哪一个 field。Key 的定义如下： (field_number &lt;&lt; 3) | wire_type //&lt;&lt;是左移运算 可以看到 Key 由两部分组成。第一部分是 field_number，比如消息 lm.helloworld 中 field id 的 field_number 为 1。第二部分为 wire_type。表示 Value 的传输类型。其中wire_type有如下几种：在我们的例子当中，field id 所采用的数据类型为 int32，因此对应的 wire type 为 0。细心的读者或许会看到在 Type 0 所能表示的数据类型中有 int32 和 sint32 这两个非常类似的数据类型。Google Protocol Buffer 区别它们的主要意图也是为了减少 encoding 后的字节数。在计算机内，一个负数一般会被表示为一个很大的整数，因为计算机定义负数的符号位为数字的最高位。如果采用 Varint 表示一个负数，那么一定需要 5 个 byte。为此 Google Protocol Buffer 定义了 sint32 这种类型，采用 zigzag 编码。Zigzag 编码用无符号数来表示有符号数字，正数和负数交错，这就是 zigzag 这个词的含义了。具体编码如图所示：使用 zigzag 编码，绝对值小的数字，无论正负都可以采用较少的 byte 来表示，充分利用了 Varint 这种技术。其他的数据类型，比如字符串等则采用类似数据库中的 varchar 的表示方法，即用一个 varint 表示长度，然后将其余部分紧跟在这个长度部分之后即可。总之，Protocol Buffer的编码确费尽心机，效果当然也不错，特别是与常用的XML相比，包括解包的速度。 了解了一下Google Protocol Buffer，算是一些课外知识了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caffe学习（7）损失层、通用层]]></title>
      <url>%2F2016%2F11%2F07%2Fcaffe%E5%AD%A6%E4%B9%A0%EF%BC%887%EF%BC%89%E6%8D%9F%E5%A4%B1%E5%B1%82%E3%80%81%E9%80%9A%E7%94%A8%E5%B1%82%2F</url>
      <content type="text"><![CDATA[Caffe LayersCaffe学习系列(5)：其它常用层及参数，denny402 损失层Loss Layers 损失通过将输出与目标进行比较，并不断优化减小loss。 Softmax（with loss） 层类型：SoftmaxWithLoss 示例： 1234567 layer &#123; name: "loss" type: "SoftmaxWithLoss" bottom: "ip1" bottom: "label" top: "loss"&#125; 在概念上等同于softmax layer+多项对数损失层（multinomial logistic loss layer），但提供了更稳定的梯度。softmax只是输出每一类的概率，并没有与label做比较。 Sum-of-Squares / Euclidean 层类型：EuclideanLoss这是比较传统的求偏差的方法，$\frac 1 {2N} \sum_{i=1}^N | x^1_i - x^2_i |_2^2$，直接计算欧氏距离。 Hinge / Margin 层类型：HingeLoss 参数(HingeLossParameter hinge_loss_param)： 可选 norm [default L1]:应该是正则化方法，目前只有L1、L2。 输入： n c h * w Predictions预测值 n 1 1 * 1 Labels标签 输出：1 1 1 * 1 Computed Loss 示例 12345678910111213141516171819# L1 Norm L1正则layer &#123; name: "loss" type: "HingeLoss" bottom: "pred" bottom: "label"&#125;# L2 Norm L2正则layer &#123; name: "loss" type: "HingeLoss" bottom: "pred" bottom: "label" top: "loss" hinge_loss_param &#123; norm: L2 &#125;&#125; Hinge loss主要用于SVM。 Accuracy 层类型：Accuracy 示例 12345678910layer &#123; name: "accuracy" type: "Accuracy" bottom: "ip2" bottom: "label" top: "accuracy" include &#123; phase: TEST &#125;&#125; 只有test阶段才有，因此需要加入include参数。它实际上不是损失并且没有后退步骤。 通用层Common Layers Inner Product 层类型：InnerProduct 参数 (InnerProductParameter inner_product_param)： 必须参数 num_output (c_o):滤波器数量。 推荐参数 weight_filler [default type: ‘constant’ value: 0]：全职初始化方式、值。还可以选择”xavier”算法来进行初始化，也可以设置为”gaussian”。 可选参数 bias_filler [default type: ‘constant’ value: 0]：偏置初始化。 bias_term [default true]: 是否启用偏置项。 输入：n c_i h_i * w_i 输出：n c_o 1 * 1 示例： 123456789101112131415161718192021layer &#123; name: "fc8" type: "InnerProduct" # learning rate and decay multipliers for the weights param &#123; lr_mult: 1 decay_mult: 1 &#125; # learning rate and decay multipliers for the biases param &#123; lr_mult: 2 decay_mult: 0 &#125; inner_product_param &#123; num_output: 1000 weight_filler &#123; type: "gaussian" std: 0.01 &#125; bias_filler &#123; type: "constant" value: 0 &#125; &#125; bottom: "fc7" top: "fc8"&#125; Reshape 层类型：Reshape 参数 (ReshapeParameter reshape_param)： 可选参数： shape 输入：单独的blob 输出：变形后的blob 示例： 1234567891011121314layer &#123; name: "reshape" type: "Reshape" bottom: "input" top: "output" reshape_param &#123; shape &#123; dim: 0 # copy the dimension from below dim: 2 dim: 3 dim: -1 # infer it from the other dimensions &#125; &#125; &#125; 这一操作不改变数据，只改变维度，也没有在过程中拷贝数据。输出的尺寸有shape参数的值规定，正数是对应的维度，除此外还有两个特殊值： 0表示复制底层对应的维度。bottom第一维度值为2，top第一维度也是2。 -1表示从其他维度推断。为了保证数据总数不变，可以根据其他维数值计算。 特别的，当时用参数：reshape_param { shape { dim: 0 dim: -1 } }时，reshape层相当于flatten层，将n c h w的数据变为n (chw)。 Concatenation 层类型： Concat 参数 (ConcatParameter concat_param)： 可选参数 axis [default 1]: 0表示沿着数量（n），1表示沿着通道（C）。 输入：n_i c_i h * w 对于每个blob输入，i= 1 到 K。 输出： 当 axis = 0: (n_1 + n_2 + … + n_K) c_1 h * w, 所有的c_i应该相同。 当 axis = 1: n_1 (c_1 + c_2 + … + c_K) h * w, 所有的n_i 应该相同。 这个层把多个blob连接为一个blob。 层的学习暂时到这里。。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caffe学习（6）激活层]]></title>
      <url>%2F2016%2F11%2F07%2Fcaffe%E5%AD%A6%E4%B9%A0%EF%BC%886%EF%BC%89%E6%BF%80%E6%B4%BB%E5%B1%82%2F</url>
      <content type="text"><![CDATA[激活（Activation）层又叫神经元（Neuron）层，最主要的是激活函数的设置。 Activation / Neuron LayersCaffe源码解析6：Neuron_Layer，楼燚航的blog 一般来说，这一层是元素级的运算符，从底部blob作为输入并产生一个相同大小的顶部blob： 输入：n c h * w 输出：n c h * w ReLU / Rectified-Linear and Leaky-ReLU 层类型：ReLU 参数(ReLUParameter relu_param)： 可选参数 negative_slope [default 0]: 用来指定负斜率部分的因子$\nu$。完整的函数表达式为：$y = \max(0, x) + \nu \min(0, x)$。反向传播的公式为$$\frac{\partial E}{\partial x} = \left{\begin{array}{lr}\nu \frac{\partial E}{\partial y} &amp; \mathrm{if} \; x \le 0 \\frac{\partial E}{\partial y} &amp; \mathrm{if} \; x &gt; 0\end{array} \right.$$ 示例（./models/bvlc_reference_caffenet/train_val.prototxt）： 123456789101112131415161718192021layer &#123; name: "relu1" type: "ReLU" bottom: "conv1" top: "conv1"&#125; ``` 支持in-place计算，bottom输入和top输出可以相同避免内存消耗。 **Sigmoid** - 层类型：Sigmoid - 示例( ./models/bvlc_reference_caffenet/train_val.prototxt)： ```pythonlayer &#123; name: "relu1" type: "ReLU" bottom: "conv1" top: "conv1"&#125; 激活函数表达式为$y = (1 + \exp(-x))^{-1}$，由于收敛速度问题现在用的不多了。 TanH、AbsVal、BNLL 层类型：TanH、AbsVal、BNLL 示例： 123456 layer &#123; name: "layer" bottom: "in" top: "out" type: "TanH"#"AbsVal"、“BNLL”官网上BNLL没有加双引号，应该是有误&#125; 分别是双曲正切函数、绝对值、binomial normal log likelihood（$f(x)=log(1 + e^x)$）的简称。 Power 层类型：Power 参数 (PowerParameter power_param)： 可选 power [default 1] scale [default 1] shift [default 0] 示例： 1234567891011 layer &#123; name: "layer" bottom: "in" top: "out" type: "Power" power_param &#123; power: 2 scale: 1 shift: 0 &#125;&#125; 幂运算函数为$f(x)= (shift + scale * x) ^ p$。 Caffe中的激活层还有很多，也有一些是加速的层。比如DropoutLayer现在是非常常用的一种网络层，只用在训练阶段，一般用在网络的全连接层中，可以减少网络的过拟合问题。具体的使用再具体看./src/caffe/layers/下的文件吧。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caffe学习（5）视觉层]]></title>
      <url>%2F2016%2F11%2F06%2Fcaffe%E5%AD%A6%E4%B9%A0%EF%BC%885%EF%BC%89%E8%A7%86%E8%A7%89%E5%B1%82%2F</url>
      <content type="text"><![CDATA[上一篇是数据层，这一篇是视觉层（Vision Layers）。参考官网和网友博客。 Vision LayersCaffe学习系列(3)：视觉层（Vision Layers)及参数，denny402Caffe源码解析5：Conv_Layer，楼燚航的blog 视觉层通常将图像作为输入，产生其他图像作为输出。图像输入可以是灰度图（通道C=1），RGB图（通道C=3）。同样图像也具有二维的空间结构，其高度$h&gt;1$宽度$w&gt;1$。大多数视觉层通过对输入区域应用特定操作产生输出的相应区域，这里就有点像传统的数字图像处理的工作了。相比之下其他层常常忽略输入的空间结构，视其为具有$chw$维度的大向量。 卷积层Convolution 层类型：Convolution CPU实现：./src/caffe/layers/convolution_layer.cpp CUDA GPU实现： ./src/caffe/layers/convolution_layer.cu 参数 (ConvolutionParameter convolution_param)： 必须参数 num_output (c_o):卷积核（filter）的个数。 kernel_size (or kernel_h and kernel_w): 卷积核大小，非方阵用_h _w。 推荐参数 weight_filler [default type: ‘constant’ value: 0]：卷积核的初始化，默认为全0，可以用”xavier”算法来进行初始化，也可以设置为”gaussian”。 可选参数 bias_term [default true]:是否开启偏置项，默认为true, 开启。 pad (or pad_h and pad_w) [default 0]: 填零操作，默认为0，不填零。是对原图进行填零，使卷积核在图像边缘能够进行卷积操作，运算后和原图的尺寸相同。扩充的时候是左右、上下对称的，比如卷积核的大小为5*5，那么pad设置为2，则四个边缘都扩充2个像素，即宽度和高度都扩充了4个像素。 stride (or stride_h and stride_w) [default 1]: 卷积核的移动步长，默认为1。 group (g) [default 1]: 分组，默认为1组。如果大于1，我们限制卷积的连接操作在一个子集内。如果我们根据图像的通道来分组，那么第i个输出分组只能与第i个输入分组进行连接。groups是代表filter 组的个数。引入gruop主要是为了选择性的连接卷基层的输入端和输出端的channels，否则参数会太多。 It was there to implement the grouped convolution in Alex Krizhevsky’s paper: when group=2, the first half of the filters are only connected to the first half of the input channels, and the second half only connected to the second half. 当group=2时，前半部分filter与输入的前半部分通道连接，后半部分filter与后半部分输入通道连接。 输入：n c_i h_i * w_i 输出：n c_o h_o w_o, where h_o = (h_i + 2 pad_h - kernel_h) / stride_h + 1 and w_o likewise。 示例 (./models/bvlc_reference_caffenet/train_val.prototxt) 1234567891011121314151617181920212223242526272829303132layer &#123; name: "conv1" type: "Convolution" bottom: "data" top: "conv1" # learning rate and decay multipliers for the # filters param &#123; lr_mult: 1 decay_mult: 1 &#125; # learning rate and decay multipliers for the biases param &#123; lr_mult: 2 decay_mult: 0 &#125; convolution_param &#123; num_output: 96 # learn 96 filters kernel_size: 11 # each filter is 11x11 stride: 4 # step 4 pixels between each filter # application weight_filler &#123; type: "gaussian" # initialize the filters from a Gaussian std: 0.01 # distribution with stdev 0.01 (default # mean: 0) &#125; bias_filler &#123; type: "constant" # initialize the biases to zero (0) value: 0 &#125; &#125;&#125; 卷积层将输入图像与一组可学习的滤波器进行卷积，每个在输出图像中产生一个特征图。 池化层Pooling Pooling 层一般在网络中是跟在Conv卷积层之后，做采样操作，其实是为了进一步缩小feature map，同时也能增大神经元的视野。 层类型：Pooling CPU实现：./src/caffe/layers/pooling_layer.cpp CUDA GPU实现：./src/caffe/layers/pooling_layer.cu 参数(PoolingParameter pooling_param)： 必须 kernel_size (or kernel_h and kernel_w)：池化核大小。 可选参数 pool [default MAX]: 池化方法，默认为MAX，还有 AVE, or STOCHASTIC。 pad (or pad_h and pad_w) [default 0]:填零。 stride (or stride_h and stride_w) [default 1]:步长。 输入：n c h_i * w_i 输出：n c h_o * w_o，h_o and w_o 与卷积层计算方法相同。 示例 ( ./models/bvlc_reference_caffenet/train_val.prototxt) 12345678910111213layer &#123; name: "pool1" type: "Pooling" bottom: "conv1" top: "pool1" pooling_param &#123; pool: MAX kernel_size: 3 # pool over a 3x3 region stride: 2 # step two pixels (in the # bottom blob) between pooling # regions &#125;&#125; 局部响应归一化层RNL 局部响应归一化层通过对局部输入区域进行归一化来执行一种“横向抑制”。具体作用感觉和特征缩放有点像，使梯度下降在所有方向上具有相同的曲率。而RNL这种方法的计算相比对每个神经元输入归一化要简单。 层类型：LRN CPU实现： ./src/caffe/layers/lrn_layer.cpp CUDA GPU实现：./src/caffe/layers/lrn_layer.cu 参数 (LRNParameter lrn_param)： 可选参数 local_size [default 5]:需要求和的通道数数目（对于跨通道LRN），或者是方形区域求和的变长（对于通道内LRN）。 alpha [default 1]: 比例参数。 beta [default 5]: 指数参数。 norm_region [default ACROSS_CHANNELS]:ACROSS_CHANNELS表示在相邻的通道间求和归一化，但没有空间延伸，即大小为local_size x 1 x 1；WITHIN_CHANNEL表示在一个通道内部特定的区域内进行求和归一化，其大小为：1 x local_size x local_size。每个输入值被除以$(1 + (\alpha/n) \sum_i x_i^2)^\beta$，$n$是每个局部区域的大小。 示例： 1234567891011layers &#123; name: "norm1" type: LRN bottom: "pool1" top: "norm1" lrn_param &#123; local_size: 5 alpha: 0.0001 beta: 0.75 &#125;&#125; Im2col Caffe中卷积操作需要先对数据进行im2col，再进行内积运算，如下图所示：]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caffe学习（4）数据层]]></title>
      <url>%2F2016%2F11%2F06%2Fcaffe%E5%AD%A6%E4%B9%A0%EF%BC%884%EF%BC%89%E6%95%B0%E6%8D%AE%E5%B1%82%2F</url>
      <content type="text"><![CDATA[数据是学习的原料，参考官网和网友的资料，来看一下数据与数据层。 Data：Ins and OutsCaffe学习系列(2)：数据层及参数，denny402 数据：输入与输出 在Caffe中，数据是以Blobs流动的（见caffe学习（1）caffe模型三种结构）。数据层的输入输出便需要由其他格式与Blobs进行相互转换。一些常见的变换如平均减法（mean-subtraction）、特征缩放是通过data layer配置完成。新的输入类型需要开发新的数据层，网络的其余部分遵循Caffe层目录的模块化。下段加载了MNIST数据：1234567891011121314151617181920212223layer &#123; name: "mnist" # Data layer loads leveldb or lmdb storage DBs for high-throughput.加载leveldb 或 lmdb类型的数据实现高吞吐量 type: "Data" # the 1st top is the data itself: the name is only convention top: "data" # the 2nd top is the ground truth: the name is only convention top: "label" # the Data layer configuration data_param &#123; # path to the DB source: "examples/mnist/mnist_train_lmdb" # type of DB: LEVELDB or LMDB (LMDB supports concurrent reads) backend: LMDB # batch processing improves efficiency. batch_size: 64 &#125; # common data transformations transform_param &#123; # feature scaling coefficient: this maps the [0, 255] MNIST data to [0, 1] scale: 0.00390625 &#125;&#125; name: 表示该层的名称，可随意取，本层为”mnist”。 type: 层类型，如果是Data，表示数据来源于LevelDB或LMDB。根据数据的来源不同，数据层的类型也不同（后面会详细阐述）。一般在练习的时候，我们都是采用的LevelDB或LMDB数据，因此层类型设置为Data。 top或bottom: 每一层用bottom来输入数据，用top来输出数据。如果只有top没有bottom，则此层只有输出，没有输入。反之亦然。如果有多个 top或多个bottom，表示有多个blobs数据的输入和输出。 data 与 label: 在数据层中，至少有一个命名为data的top。如果有第二个top，一般命名为label。 这种(data,label)配对是分类模型所必需的。本例中第一个top是数据本身，第二个top是label（ground truth）（这些名字只是约定的）。 include: 一般训练的时候和测试的时候，模型的层是不一样的。该层（layer）是属于训练阶段的层，还是属于测试阶段的层，需要用include来指定。如果没有include参数，则表示该层既在训练模型中，又在测试模型中。（上例中没有出现） 123include &#123; phase: TRAIN #仅在训练中出现 &#125; Transformations: 数据的预处理，可以将数据变换到定义的范围内。如设置scale为0.00390625，实际上就是1/255, 即将输入数据由0-255归一化到0-1之间。除了缩放，还有其他的一些预处理操作： 12345678transform_param &#123; scale: 0.00390625 mean_file_size: "examples/cifar10/mean.binaryproto" # 用一个配置文件来进行均值操作 mirror: 1 # 1表示开启镜像，0表示关闭，也可用ture和false来表示 # 剪裁一个 227*227的图块，在训练阶段随机剪裁（random cropping），在测试阶段从中间裁剪 crop_size: 227 &#125; prefetching：预取，对于吞吐量数据层获取下一批数据，并在Net计算当前批处理时在后台准备。 具体的还需要分析data_param，data_param部分，就是根据数据的来源不同，来进行不同的设置。 数据来自于数据库（如LevelDB和LMDB）层类型（layer type）:Data 必须设置的参数：source: 包含数据库的目录名称batch_size: 每次处理的数据个数，如64 可选的参数：rand_skip: 在开始的时候，跳过一定数量的数据输入，通常对异步的SGD很有用（useful for asynchronous sgd）。backend: 选择是采用LevelDB还是LMDB, 默认是LevelDB.示例： 123data_param &#123; source: "examples/mnist/mnist_train_lmdb" batch_size: 64&#125; 数据来自于内存层类型：MemoryData 必须设置的参数：batch_size：每一次处理的数据个数，比如2channels：通道数height：高度width: 宽度即指定要从内存中读取的输入块的大小。存储器数据层直接从存储器读取数据，而不复制它。为了使用它，必须调用MemoryDataLayer :: Reset（C ++）或Net.set_input_arrays（Python），以便指定一个连续数据源（作为4D行主数组），一次读取一个批处理大小的块。示例： 1234567891011121314151617 layer &#123; top: "data" top: "label" name: "memory_data" type: "MemoryData" memory_data_param&#123; batch_size: 2 height: 100 width: 100 channels: 1 &#125; transform_param &#123; scale: 0.0078125 mean_file: "mean.proto" mirror: false &#125;&#125; 数据来自于HDF5(Input)层类型：HDF5Data 必须设置的参数：source: 读取的文件名称batch_size: 每一次处理的数据个数示例： 12345678910layer &#123; name: "data" type: "HDF5Data" top: "data" top: "label" hdf5_data_param &#123; source: "examples/hdf5_classification/data/train.txt" batch_size: 10 &#125;&#125; 数据输出到HDF5(Output)层类型：HDF5Data 必须设置的参数：file_name: 输出到的文件名称HDF5输出层执行与本节中其他层相反的功能：它将其输出blob写入磁盘。 数据来自于图片层类型：ImageData 必须设置的参数：source: 一个文本文件的名字，每一行给定一个图片文件的名称和标签（label）batch_size: 每一次处理的数据个数，即图片数 可选参数：rand_skip: 在开始的时候，跳过一定的数据输入。通常对异步的SGD很有用。shuffle: 随机打乱顺序，默认值为falsenew_height,new_width: 如果设置，则将图片进行resize示例：1234567891011121314151617layer &#123; name: "data" type: "ImageData" top: "data" top: "label" transform_param &#123; mirror: false crop_size: 227 mean_file: "data/ilsvrc12/imagenet_mean.binaryproto" &#125; image_data_param &#123; source: "examples/_temp/file_list.txt" batch_size: 50 new_height: 256 new_width: 256 &#125;&#125; 数据来源于Windows层类型：WindowData 必须设置的参数：source: 一个文本文件的名字batch_size: 每一次处理的数据个数，即图片数示例：1234567891011121314151617181920212223 layer &#123; name: "data" type: "WindowData" top: "data" top: "label" include &#123; phase: TRAIN &#125; transform_param &#123; mirror: true crop_size: 227 mean_file: "data/ilsvrc12/imagenet_mean.binaryproto" &#125; window_data_param &#123; source: "examples/finetune_pascal_detection/window_file_2007_trainval.txt" batch_size: 128 fg_threshold: 0.5 bg_threshold: 0.5 fg_fraction: 0.25 context_pad: 16 crop_mode: "warp" &#125;&#125; DummyDummyData用于调试，详见DummyDataParameter。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caffe学习（3）接口]]></title>
      <url>%2F2016%2F11%2F06%2Fcaffe%E5%AD%A6%E4%B9%A0%EF%BC%883%EF%BC%89%E6%8E%A5%E5%8F%A3%2F</url>
      <content type="text"><![CDATA[接口Interfaces Interfaces Caffe提供丰富的接口，比如命令行，python，matlab。先说一下命令行 命令行 caffe命令及其参数解析，Single、Dog Caffe的程序位于caffe / build / tools，运行时可以在根目录执行./build/tools/caffe &lt;command&gt;&lt;args&gt;。其中&lt;command&gt;有四种： train：训练或finetune模型(model) test：测试模型 device_query：显示gpu信息 time：显示程序执行时间 其中的&lt;args&gt;参数有： -solver -gpu -snapshot -weights -model -sighup_effect -sigint_effect 训练traincaffe train可以从头开始学习模型、从已保存的快照中恢复学习或添加新数据进行fine-tunes。具体来说，所有训练需要通过-solver solver.prototxt参数进行求解器配置；恢复需要使用-snapshot model_iter_1000.solverstate参数来加载求解程序快照；fine-tunes微调需要模型初始化的-weights model.caffemodel参数。 12345678# train LeNet 训练LeNetcaffe train -solver examples/mnist/lenet_solver.prototxt# train on GPU 2 在特定的GPU上caffe train -solver examples/mnist/lenet_solver.prototxt -gpu 2# resume training from the half-way point snapshot 从快照恢复caffe train -solver examples/mnist/lenet_solver.prototxt -snapshot examples/mnist/lenet_iter_5000.solverstate# fine-tune CaffeNet model weights for style recognition 完整例子参阅examples/finetuning_on_flickr_style，仅调用可使用：caffe train -solver examples/finetuning_on_flickr_style/solver.prototxt -weights models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel 对于train的参数，功能为： -solver：必选，后跟一个protocol buffer类型(.prototxt)的文件，即模型的配置文件。 -gpu：可选，指定某一块GPU运行，-gpu all是所有运行： 1234# train on GPUs 0 &amp; 1 (doubling the batch size)caffe train -solver examples/mnist/lenet_solver.prototxt -gpu 0,1# train on all GPUs (multiplying batch size by number of devices)caffe train -solver examples/mnist/lenet_solver.prototxt -gpu all -snapshot：可选，从快照中恢复，设置快照可从solver配置中进行，保存为solverstate。 -weights：可选参数。用预先训练好的权重来fine-tuning模型，需要一个caffemodel，不能和-snapshot同时使用。 -iterations： 可选参数，迭代次数，默认为50。 如果在配置文件文件中没有设定迭代次数，则默认迭代50次。 -model：可选参数，定义在protocol buffer文件中的模型。也可以在solver配置文件中指定。 -sighup_effect：可选参数。用来设定当程序发生挂起事件时，执行的操作，可以设置为snapshot, stop或none, 默认为snapshot。 -sigint_effect： 可选参数。用来设定当程序发生键盘中止事件时（ctrl+c), 执行的操作，可以设置为snapshot, stop或none, 默认为stop。测试test测试时输出每个batch得分，最后返回平均值。test参数用在测试阶段，用于最终结果的输出，要模型配置文件中我们可以设定需要输入accuracy还是loss. 假设我们要在验证集中验证已经训练好的模型，就可以这样写123# score the learned LeNet model on the validation set as defined in the# model architeture lenet_train_test.prototxtcaffe test -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -gpu 0 -iterations 100 意思是利用训练好了的权重（-weight)，输入到测试模型中(-model)，用编号为0的gpu(-gpu)测试100次(-iteration)。 时间timetime参数用来在屏幕上显示程序运行时间。如：123# (These example calls require you complete the LeNet / MNIST example first.)# time LeNet training on CPU for 10 iterationscaffe time -model examples/mnist/lenet_train_test.prototxt -iterations 10 这个例子用来在屏幕上显示lenet模型迭代10次所使用的时间。包括每次迭代的forward和backward所用的时间，也包括每层forward和backward所用的平均时间。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caffe学习（2）前后传播，loss，solver]]></title>
      <url>%2F2016%2F11%2F06%2Fcaffe%E5%AD%A6%E4%B9%A0%EF%BC%882%EF%BC%89%E5%89%8D%E5%90%8E%E4%BC%A0%E6%92%AD%EF%BC%8Closs%EF%BC%8Csolver%2F</url>
      <content type="text"><![CDATA[向前和向后传播 Forward and Backward 前后传播是Net的重要组成，如下图所示： 向前Forward通过给定的参数计算每层的值，就像函数一样top=f(bottom)。上图表示数据通过内积层输出，再由softmax给出损失。 向后Backward向后是计算loss的梯度，每层梯度通过自动微分来计算整个模型梯度，即反向传播。从这个图上可以看出，由loss开始，通过链式法则，不断求出结果对各层的导数。Net::Forward()和Net::Backward()是针对网络，Layer::Forward()和Layer::Backward()是针对每一层。同时也可以设置CPU、GPU模式。过程大概是：solver调用forward计算输出和loss，再生成梯度，并尝试更新权重减小loss。 损失Loss Loss Loss使loss变小，是学习中的一个目标。如上所说，loss是由forward计算而出。1234567layer &#123; name: "loss" type: "SoftmaxWithLoss" bottom: "pred" bottom: "label" top: "loss"&#125; 这一段就是上面流程图最后一层loss的表达。 Loss weights一般的loss只是最后一层才有，其他层只是中间计算，不过每层都可以通过增加loss_weight: &lt;float&gt;到该层生成的每个顶（top）层中。对于后缀有loss的层都隐含着loss_weight: 1（对第一个top，其他的loss_weight: 0）。因此上面代码也等价于在最后加上loss_weight: 1。然而任何能反向传播的层都可以赋予非零loss_weight，最终的loss由网络上各层loss权重求得1234loss := 0for layer in layers: for top, loss_weight in layer.tops, layer.loss_weights: loss += loss_weight * sum(top) Solver Solver 分类Solver通过forward和backward形成参数更新，从而改善loss。包括： Stochastic Gradient Descent (type: “SGD”), AdaDelta (type: “AdaDelta”), Adaptive Gradient (type: “AdaGrad”), Adam (type: “Adam”), Nesterov’s Accelerated Gradient (type: “Nesterov”) and RMSprop (type: “RMSProp”) 方法对于数据集$D$，优化目标是使整个$|D|$的平均loss最小，即：$$L(W) = \frac{1}{|D|} \sum_i^{|D|} f_W\left(X^{(i)}\right) + \lambda r(W)$$其中$f_W\left(X^{(i)}\right)$是对于数据$X^{(i)}$输入的损失，$r(W)$是加权$\lambda$的权重$W$正则项。通常用于学习的数据量$|D|$很大，在学习时常常将其分为很多大小为$N$的batch，其中$N&lt;&lt;|D|$，可以将原式中的$|D|$换为$N$。$$L(W) \approx \frac{1}{N} \sum_i^N f_W\left(X^{(i)}\right) + \lambda r(W)$$模型向前计算$f_W$，向后返回梯度$\nabla f_W$。参数的更新$\Delta W$由solver从$\nabla f_W$得到，正则化梯度每种方法得到的不同。具体每种solver，网上讲的很多，这里就不讲了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[caffe学习（1）caffe模型三种结构]]></title>
      <url>%2F2016%2F11%2F05%2Fcaffe%E5%AD%A6%E4%B9%A0%EF%BC%881%EF%BC%89caffe%E6%A8%A1%E5%9E%8B%E4%B8%89%E7%A7%8D%E7%BB%93%E6%9E%84%2F</url>
      <content type="text"><![CDATA[caffe模型三种结构 自己写的然而CSDN出bug了，绑定三方账户原来的博客无法编辑，只好转发过来 Blobs, Layers, and Nets: anatomy of a Caffe modelBlob：存储和传递（communication）blob是数据存储和传输的包装，并且还在底层提供CPU和GPU之间的同步能力。Blob提供了保存数据的统一存储器接口； 例如图像批次，模型参数和用于优化的导数。 在数学上，blob是以C连续方式（C-contiguous fashion）存储的N维数组。 关于C连续方式，stackoverflow有一个解释。该方式主要与Fortran和Matlab相反，是一种以行为主顺序（Row-major order）的存储方式，简单的说就是把一行存完，再存下一行，把第一个通道（channel）的所有行写完后写完再写下一个通道。例如对一批（batches）图像，用4维blob存储，表示为number N（数据批量大小） x channel K（通道、维度特征） x height H （高）x width W（宽），对于索引 (n, k, h, w) 的物理地址就是：((n K + k) H + h) W + w，注意区分大小写，大写是总的，小写是索引值。对于图像是4D的，当然也可以不用4D。具体参数需要根据层类型和数据大小配置。 blob使用了两块存储区域，为data（数据）和diff（网络梯度），实际值可以存储在CPU或GPU上，访问也可以不变（const）访问或者可变（mutable）访问。 const Dtype cpu_data() const; Dtype* mutable_cpu_data(); 同理可得GPU上diff类型数据操作。官网上有一个example，展示了数据在CPU和GPU上流动操作。Layer计算和连接Layer包括很多计算方法，如Vision Layers：Convolution、Pooling、LRNLoss Layers：Softmax、Sum-of-Squares既然作为计算，就有输入输出，输入从底部（bottom）获取，并通过顶部（top）连接输出。每层须有三个关键计算：setup, forward, and backward。setup：初始化层和连接。forward：底部向顶部计算。backward：给定梯度，从top计算传回bottom。A layer with parameters computes the gradient w.r.t. to its parameters and stores it internally.（是说存在layer中吗）forward和backward也分为CPU和GPU两个版本。 If you do not implement a GPU version, the layer will fall back to the CPU functions as a backup option. This may come handy if you would like to do quick experiments, although it may come with additional data transfer cost 这里好像是说使用GPU会因为数据需要从CPU复制到GPU上，因此会有数据传输成本，但GPU跑的还是快一些，所以是quick experiments。Net定义和操作Net由Layer组成（The net is a set of layers connected in a computation graph有向无环图）。模型初始化由Net :: Init（）处理：主要是创建blob和layer，并调用layer里的setup，同时会输出INFO。模型格式模型定义在.prototxt文件中，训练好的模型在model目录下.binaryproto格式的文件中，模型的格式由caffe.proto定义。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Caffe运行MNIST | example]]></title>
      <url>%2F2016%2F10%2F09%2Fcaffe-e8-bf-90-e8-a1-8cmnist-example%2F</url>
      <content type="text"><![CDATA[参考教程测试一下caffe。 1.获取数据包。 cd $CAFFE_ROOT ./data/mnist/get_mnist.sh ./examples/mnist/create_mnist.sh 官网上是这样的，caffe_root是根目录，看网上有人说必须在根目录下运行，否则会出错，具体没有验证。。但是windows平台下应该是没有wget的，需要自己下载一下。得到四个文件，测试与训练，样本与标签。 第二句是个坑，直接执行的话会提示找不到convert_mnist_data.bin（好像是这个）。这个环境还是linux下的，windows下编译出来的是exe，和caffe在一起。用法是 convert_mnist_data [FLAGS] input_image_file input_label_file output_db_file执行两次将mnist date转化为可用的lmdb格式的文件。并将新生成的2个文件mnist-train-lmdb 和 mnist-test-lmdb放于create_mnist.sh同目录下。 2.测试 参数文件用的是 ./build/tools/caffe train –solver=examples/mnist/lenet_solver.prototxt mnist_test_lmdb mnist_train_lmdb 两个文件夹需要放在\examples\mnist。如果像我没用GPU，还需要在.prototxt里面更改solver_mode为 CPU。 感觉跑了一个半小时吧，终于跑完了。生成了四个文件……数据都训练好之后，接下来就是如何将模型应用到实际数据了（记录的博客）： ./build/tools/caffe.bin test -model=examples/mnist/lenet_train_test.prototxt -weights=examples/mnist/lenet_iter_10000.caffemodel -gpu=0 如果没有GPU则使用 ./build/tools/caffe.bin test -model=examples/mnist/lenet_train_test.prototxt -weights=examples/mnist/lenet_iter_10000.caffemodel看起来准确率很高。 Training LeNet on MNIST with Caffe]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Caffe | Installation caffe 安装]]></title>
      <url>%2F2016%2F10%2F05%2Fcaffe-installation-caffe-e5-ae-89-e8-a3-85%2F</url>
      <content type="text"><![CDATA[尝试下caffe在windows的安装。 本本用的还是A卡，干脆禁掉CUDA和cuDNN吧，换新的重新安装再配置。 &lt;CpuOnlyBuild&gt;true&lt;/CpuOnlyBuild&gt;&lt;UseCuDNN&gt;false&lt;/UseCuDNN&gt;&lt;PythonSupport&gt;true&lt;/PythonSupport&gt;之后是python，之前装过又删掉了，这次再装一遍吧。windows下推荐的是Miniconda环境，里面集成了python2.7。运行 conda install --yes numpy scipy matplotlib scikit-image pip pip install protobuf 是在Miniconda2文件夹中cmd里面运行的，会自动下载安装一些库，本机下载了250M左右，第一次下载到第二个就卡住了QAQ，然后关了之后再输说之前存在任务触发保护了需要解锁，输入以下命令解锁。 conda clean –lock虚拟环境创建操作参考了conda简单使用，一开始一直在python里面输命令，好蠢= =miniconda只是一个方便配置python的虚拟环境，里面python可以根据需要再加自己要的库。这个步骤应该是在前面的库安装完了之后再进行，否则新安装的库好像不会在老的环境里出现。删除原有环境： conda remove –name 此处是环境名字 –all其他没有怎么设置了，直接用vs2013打开编译…… 但是感觉过了一年，卡在了这里： nuget好像也是一个管理库的插件，会自动下载各种东西，然而下载速度简直无语。。感觉过了几个小时下载好了，多了900MB东西。然后build……又是一堆错误。 首先是libcaffe.lib无法生成，其中两个小问题，找不到layer_factory.h和pyconfig.h，分别在caffe目录中和python目录中。之后找不到python27.lib，也在python中libs里，但是还会有一堆warning，不管了。。 最后终于都build完成，Debug版的出来1.8G，release版的提示nuget超时，不太清楚原因。python部分把生成出来的拷到python目录\lib\site-packages，import一下应该就可以了。 测试的话用的生成出来的test_all.exe，一开始跑得还快，后面的单项都能到40多秒，果然学习不是轻松的事情= =出现一些错误，好像是找不到测试图片，所以程序上应该没有错了。 哎，编译不易，还须多珍惜。 来源： Caffe | Installation]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[出发|关服]]></title>
      <url>%2F2016%2F09%2F21%2Fe5-87-ba-e5-8f-91-e5-85-b3-e6-9c-8d%2F</url>
      <content type="text"><![CDATA[明天出发，跑个三角形，树莓派可以休息啦。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[机会还是会留给有准备的人啊~]]></title>
      <url>%2F2016%2F09%2F19%2Fe6-9c-ba-e4-bc-9a-e8-bf-98-e6-98-af-e4-bc-9a-e7-95-99-e7-bb-99-e6-9c-89-e5-87-86-e5-a4-87-e7-9a-84-e4-ba-ba-e5-95-8a%2F</url>
      <content type="text"><![CDATA[这段时间这么盲目、慌张，也好久没有这样的感觉了，可能习惯了按部就班的生活…… 简单说学到了几点： 1.计划可能真的赶不上变化，事情没有发生就不能确定，也要留后手。 2.多准备，不能把鸡蛋装一个篮子里。 3.要有一定的紧张感，居安思危。 &nbsp; PS：树莓派工作了好几天没休息，不知道有没有事。。 过几天如果出远门就关了]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[从flash到手游]]></title>
      <url>%2F2016%2F09%2F13%2Fe4-bb-8eflash-e5-88-b0-e6-89-8b-e6-b8-b8%2F</url>
      <content type="text"><![CDATA[近日室友又重新怀旧，玩起了金庸群侠传这个flash游戏。老实说我对这个游戏印象并不是很深，因为一没读过金庸，二来游戏确实很复杂，系统、任务众多，不是简单的休闲游戏。在我看来，这样一个出色的rpg游戏，可以算是flash游戏的巅峰了。如果是一个pc游戏，可能反而没有这么大的影响力。 03、04年，大概是小学三四年级的时候，电脑已经比较普遍了，特别是在我们小学已经开始上微机课了。更重要的一点是宽带取代了拨号上网，再也没有了奇奇怪怪叽叽喳喳的拨号声音，速度也能到几百k。有了网络物质基础，就需要寻求网络娱乐内容。在家里，梦幻西游、大话西游成了大家的首选（至少是男生吧），回家总是会打开玩一会儿。神奇的是我没有在这两个游戏上充过点卡，要不是自己就玩个免费的阶段（10级前吧），要不就玩同学的号。网吧更多的可能是cs、流星蝴蝶剑的天下，但是我也一次没有去过。而在学校，flash游戏成了班上所有同学的选择，优点显而易见：无需安装打开就玩；体积小，最多加载个一分钟；类型多，打开4399这类网站，光游戏分类就琳琅满目，每个人都能找到自己所需要的。于是微机课上完自由活动的时间，也就成了班上flash游戏的时间。flash游戏分类里面有一个双人小游戏，这是我和小伙伴最喜欢的。常常和小伙伴两个人挤在一张电脑桌前，还好当时手小，键盘放四只手也没问题，愉快的游戏时间就开始了。这可能就是小时候的“开黑”吧~ 那时我们突然意识到，除了打球、踢球这种运动，原来还有游戏这个虚拟的空间能够让我们站在一起，或是并肩作战，或是相互厮杀。因此本质上，游戏应该和其他的运动项目没有什么区别。胜利有时也不是必须的，不是常说友谊第一比赛第二吗？人与人之间的关系才是重要的。 不过这么多年过去了，无论是游戏，还是玩游戏的人，似乎都变了很多。 flash游戏受限于平台，难以做得更好，移动端随着智能手机逐渐发力，手游如雨后春笋不断出现。金庸群侠传原作者半瓶神仙醋，也亲自投身于手游开发。然而手游看似更为休闲，但实际上往里面投钱的并不少。这又是为什么呢？ 或许是曾经的关系搞反了。现在网络更方便，人们可以从网上认识到更多的人，甚至早于在现实中相识。因此想要得到对方的认同的话，游戏中的一堆数字是最好的证明。而最简单的方法就是充值……这么看来，游戏更是一种炫耀、渴望被认同的一种手段。当初和现实朋友一起奋战的感觉变得更少了。 但是另一方面，游戏业也在这种氛围中钱越赚越多。半瓶神仙醋的微博，还停留在去年，其中靠前的一条是给自己的手游《冒险王2》宣传，而金庸群侠传4好像已经无限跳票，做免费游戏当然不能是他的义务，玩家自然不能强迫。毕竟如今35岁，可能再也追不回之前的梦了。我想我可能也是如此吧，十年后又能记得起如今的梦吗？还是定一个小目标：十年后还能记得起十年前身边的人，和与这些人一起的故事吧。 &nbsp; 自慰诗 半瓶神仙醋， 生于冀中， 学于湘潭， 混迹于京师。 苟活二十有五， 孑然一身， 惨淡经营， 做此游戏， 聊已慰藉。 不求闻达于诸侯， 不甘堕落于俗事。 虽勤勉学习， 艰苦奋斗， 仍然一事无成， 可叹造化弄人也. （此为2006年金庸群侠传2中所作）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[初次评论无需审核]]></title>
      <url>%2F2016%2F09%2F08%2Fe5-88-9d-e6-ac-a1-e8-af-84-e8-ae-ba-e6-97-a0-e9-9c-80-e5-ae-a1-e6-a0-b8%2F</url>
      <content type="text"><![CDATA[应该是这个设置吧，以后大家评论也不用经过审核了，我审起来也麻烦。。 PS：检查卫生说我桌子乱不是一次两次了，这次为了收拾桌子就把树莓派收起来了，今天服务器就没开= =]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[祝你有美好的一天'√']]></title>
      <url>%2F2016%2F09%2F07%2Fe7-a5-9d-e4-bd-a0-e6-9c-89-e7-be-8e-e5-a5-bd-e7-9a-84-e4-b8-80-e5-a4-a9-e2-88-9a%2F</url>
      <content type="text"><![CDATA[如果你有幸和我到ktv，那么一定不会错过一首歌：Have a nice day。 虽然嗓音不行，但是瞎喊喊就很爽了，唱歌不就是为了表达宣泄感情吗？ 不过说到这首歌，不得不提这首歌的乐队：Bon Jovi。 最初接触他们是小学在某电视节目上，放的CS的视频，BGM就是It’s my life，这也是我认为是最被国人所知的一首歌。视频里精彩的击杀镜头被这首歌衬托得十分酷炫，不过当时可能更多的激起了玩游戏的欲望…… 这首歌始终被埋在记忆深处，直到初中开始学习英语，英语老师让我们学唱一首英文歌。一开始选的是You are my sunshine，反光镜乐队版，很短很简单= =会唱之后很没有成就感，就想再试试其他歌，不知怎么，It’s my life就悄悄在脑中响起……最后在课上老师让我演唱一曲，我也不知道最后唱的哪一个，但是五音不全是肯定的。 唱歌受挫，听歌总不会如此。我便更多地去了解这个乐队，Have a nice day、Bounce、Always等一首首加入了我的mp3。至少在初中、高中这段紧张的学习生涯中给了我很多动力。 Oh, if there’s one thing I hang onto that gets me through the night I ain’t gonna do what I don’t want to; I’m gonna live my life Shining like a diamond, rolling with the dice Standing on the ledge, I show the wind how to fly When the world gets in my face, I say Have a nice day！ 《Have a nice day》 初高中听这种歌是为了提神，因为每天辛苦的学习可能都不是我们所希望做的，或者说”live my life”。但我们可以把这个过程当作”live my life”的准备，“考上大学就能live my life”了。事实如此吗？大学里好像也只是按着课程，为了成绩、排名而努力，量化到了一个数字，这就是“life”吗？是自己的“life”还是别人规划好的“life”呢？可能我只是把别人交给的任务努力做的优秀罢了。 [caption id=”attachment_39” align=”aligncenter” width=”300”] ‘√’[/caption] 不过我也希望有一天能够找到自己的“life”，因此从初二开始，这个专辑封面一直作为了我的头像，希望Have a nice day，也希望live my life。PS：今年Bon Jovi又发了新专，This House Is Not for Sale，毕竟62年出生的人了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[发微博啦~ Joy是小一一]]></title>
      <url>%2F2016%2F09%2F03%2Fe5-8f-91-e5-be-ae-e5-8d-9a-e5-95-a6-joy-e6-98-af-e5-b0-8f-e4-b8-80-e4-b8-80%2F</url>
      <content type="text"><![CDATA[如果再加上if weibo then wordpress会不会无限循环啊。。[笑cry] (via Weibo http://ift.tt/2c0xa0b)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[微博的朋友们你们好吗]]></title>
      <url>%2F2016%2F09%2F03%2Fe5-be-ae-e5-8d-9a-e7-9a-84-e6-9c-8b-e5-8f-8b-e4-bb-ac-e4-bd-a0-e4-bb-ac-e5-a5-bd-e5-90-97%2F</url>
      <content type="text"><![CDATA[把wordpress和weibo连起来了，这么说我发一条文章就会自动发一条微博咯？ 测试一下]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Real or Not]]></title>
      <url>%2F2016%2F09%2F03%2Freal-or-not%2F</url>
      <content type="text"><![CDATA[美剧有个特点，就是有点长，还拖成好几季，比如之前看的南方公园，目前估计都要二十季了吧。入坑还是要谨慎。 然而我还是经不住诱惑开始看Rick and Morty了……不得不说脑洞太大，动画的形式充分展现了无边的想象力。 比如虚拟（Rick and Morty (e4)）和梦境（Rick and Morty (e2) ）的两集，分别讲述二人在人工制造的虚拟城市和多层梦境（有点像盗梦空间）的冒险。这种经历往往会让人对虚拟和现实产生一定的疑问。 当然很多人都开始了这种思考，特别是人们逐渐了解人体、生命之间的秘密和联系之后，发现很多都是可以解释和人工产生的。最疯狂的可能是“缸中之脑”这个概念。这是希拉里·普特南（Hilary Putnam）1981年在他的《理性，真理与历史》（Reason, Truth, and History）一书中，阐述的假想。艺术作品也对这种设定情有独钟，频频出现于各种科幻剧里，个人感觉《黑客帝国》是最著名的。 那么问题来了，如果有一天发现世界并不是真实的，应该怎么办？似乎这比今天吃什么还要难以抉择。 即使是虚拟的世界，但通过努力完成了一定的工作量，在这个世界中有所贡献，似乎也是不能轻言放弃的，就像minecraft中一个个宏伟的工程。同样与他人之间的关系也很重要，不过如果得知其他所有的人都是虚拟出来，只是AI的话一定很难以接受。哪个选择才是正确的，或许并不重要，而在虚拟中和真实中度过一生又有什么不同呢？ 如果这种事情发生在我身上，具体应该如何选择，的确是需要好好考虑一番。但是让我用一句话总结的话，还是选择一个更需要我的世界吧。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[去健身吧~]]></title>
      <url>%2F2016%2F09%2F01%2Fe5-8e-bb-e5-81-a5-e8-ba-ab-e5-90-a7%2F</url>
      <content type="text"><![CDATA[去健身吧~ （其实去年我也是这么说的） 最初的原因其实是看了一部JoJo的动漫，人物的画风大概是这样的： &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 以及这样 感觉好强啊= =，对于习惯正常日漫萌系画风的我还是有一定的冲击（特别是这些羞耻？的造型。。）。不过就剧情来讲，差不多每一场战斗都是靠的脑子取胜的，看起来还是很有意思。 于是我也开始了跟风办了健身卡，大二下学期尽量保证每周至少去了一次……发现没什么用。。。 现在有了时间（才不是看了新的动漫），尽量养成健身的习惯吧。而且这办卡还是去了三次才办成，来之不易，更应该好好珍惜。 那么一起加油吧~ 最后！！！！！《99》完整版出了！！！！不来听一下吗？ [audio mp3=”http://yanjoy.win/wp-content/uploads/MOB-CHOIR-99.mp3&quot;][/audio]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[上传文件限制解除]]></title>
      <url>%2F2016%2F08%2F31%2Fe4-b8-8a-e4-bc-a0-e6-96-87-e4-bb-b6-e9-99-90-e5-88-b6-e8-a7-a3-e9-99-a4%2F</url>
      <content type="text"><![CDATA[想添加首歌，然而打开添加媒体…… “最大上传文件大小：2MB。” ？？？什么年代了这种限制简直不够看啊！ 还好大家都是这么想的 先是参考wpyou.com，三种方法都尝试了结果都不行，特别是第二个找不到php.ini，自己在根目录创建了一个。但是眉头一皱感觉事情没有那么简单 查找资料发现限制大小的其实是php，那么php.ini应该在php目录中。参考冰莫言php安装路径，果然找到了，然而不止一个： 这里面3、4个目录都有php.ini。。所以都改了吧= =，把upload_max_filesize 由2M改到64M。心满意足~~~~ 干完之后发现果然增加了！！！！增到8M了！！ ？？？？跟说好的不一样啊！！！莫非是大意了？ 再看一下文章，果然我只改了upload，还有post_max_size 没改。一看post_max_size=8M，对这个数字很熟悉啊，看来上传媒体文件不能大于post大小限制。 而且jb51.net上有更详细的说明，顺便改了wp-config.php的内容。 一切完工，成功了~ PS：早知道改这么麻烦就把限制再放开些了 [playlist ids=”74”]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[树莓派搭建wordpress|心路历程（雾]]></title>
      <url>%2F2016%2F08%2F30%2Fe6-a0-91-e8-8e-93-e6-b4-be-e6-90-ad-e5-bb-bawordpress-e5-bf-83-e8-b7-af-e5-8e-86-e7-a8-8b-ef-bc-88-e9-9b-be%2F</url>
      <content type="text"><![CDATA[项目这几个月都没有动，两个树莓派就放那里不断吃灰= = 为了废物利用（？）还是随便建个小站玩玩吧。 虽然说wp是个很傻嗨的东西，但现在还没有完全搞定。。 首先参考的是果壳及其引文，采用的是nginx。照着做到最后一步，wp-admin/install.php 打不开QAQ是一片空白。。 之后删了nginx换apache，然而……还是这样 联想到第四步和实际情况的不符 在/var/www目录下新建一个index.php文件： $ sudo nano /var/www/index.php 在这个文件里只需写入一行： 保存并退出编辑。删除该目录下的index.html文件，再次用浏览器打开Apache服务器的默认起始页面，应该能够看到PHP的配置信息。 感觉可能是index没放对地方。/www 里面还有个 /html，放进这里才能显示。。 这么说我把wordpress放在/www 里面没有卵用，放到/www/html 里面才行。 结果肯定是成功了（要不就没有这些东西了） 可是更新功能全跪（无法创建目录），另外无法从wp上传文件（显示上传成功在服务器上找不到） 网上所有的方法其实都一样——给权限。但是疯狂给权限之后还是不行啊~~~ 上传服务器有人说改一下uploadspath，改成/wp-content/uploads 就可以了，实践后貌似没用，就干脆改成全路径/usr/share/wordprees 也加上竟然可以了（玄学 所以忙了大概一天，解决了这些东西 感觉自己什么都不会 用树莓派建LAMP+WordPress服务器树莓派Raspberry Pi讨论区技术论坛云汉电子社区来源： 用树莓派建LAMP+WordPress服务器树莓派Raspberry Pi讨论区技术论坛_云汉电子社区_ &nbsp; PS：拿这个当第一篇博文貌似并不文艺，写博客的初衷是啥呢？重拾文艺撩妹]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[小站开工]]></title>
      <url>%2F2016%2F08%2F29%2Fe5-b0-8f-e7-ab-99-e5-bc-80-e5-b7-a5%2F</url>
      <content type="text"><![CDATA[差不多干了一天，只剩下插件和主题两片乌云]]></content>
    </entry>

    
  
  
</search>

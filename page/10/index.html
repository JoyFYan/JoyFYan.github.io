<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



















  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/favicon.ico?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16.png?v=6.3.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Default~">
<meta property="og:type" content="website">
<meta property="og:title" content="小一一的小站">
<meta property="og:url" content="https://joyfyan.github.io/page/10/index.html">
<meta property="og:site_name" content="小一一的小站">
<meta property="og:description" content="Default~">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="小一一的小站">
<meta name="twitter:description" content="Default~">






  <link rel="canonical" href="https://joyfyan.github.io/page/10/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>小一一的小站</title>
  






  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?59765bbe651ba5fb69dc22dd74eb6ba7";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">小一一的小站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Blog of Yan Joy</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />About</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />Tags</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />Categories</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />Archives</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />Search</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://joyfyan.github.io/2016/11/09/caffe学习（11）python的数据可视化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yan Joy">
      <meta itemprop="description" content="Default~">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小一一的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/11/09/caffe学习（11）python的数据可视化/" itemprop="url">
                  caffe学习（11）python的数据可视化
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-11-09 16:24:00" itemprop="dateCreated datePublished" datetime="2016-11-09T16:24:00+08:00">2016-11-09</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2016-11-18 15:31:22" itemprop="dateModified" datetime="2016-11-18T15:31:22+08:00">2016-11-18</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2016/11/09/caffe学习（11）python的数据可视化/" class="leancloud_visitors" data-flag-title="caffe学习（11）python的数据可视化">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views: </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>caffe本身没有可视化的工具，一般需要配合python或matlab实现数据的可视化，在实践本文之前要先把caffe python编译好。另外有的服务器只有shell，没有可视化的界面，只好先把每一层的数据先保存成图片格式，再进行显示。</p>
<blockquote>
<p><a href="http://www.cnblogs.com/denny402/p/5092075.html" target="_blank" rel="external">Caffe学习系列(14)：初识数据可视化</a><br><a href="http://caffe.berkeleyvision.org/installation.html" target="_blank" rel="external">Python and/or MATLAB Caffe (optional)</a></p>
</blockquote>
<hr>
<h2 id="载入数据"><a href="#载入数据" class="headerlink" title="载入数据"></a>载入数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> caffe</div><div class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io</div><div class="line">caffe_root=<span class="string">'/home/XXX/caffe/'</span></div><div class="line"><span class="keyword">import</span> os,sys</div><div class="line">os.chdir(caffe_root)</div><div class="line">sys.path.insert(<span class="number">0</span>,caffe_root+<span class="string">'python'</span>)</div><div class="line">im = caffe.io.load_image(<span class="string">'examples/images/cat.jpg'</span>)</div><div class="line">io.imsave(<span class="string">'cat.jpg'</span>,im)</div><div class="line"><span class="keyword">print</span> im.shape</div></pre></td></tr></table></figure>
<p>这里用到了skimage 这个库，caffe用于读取图像的函数<code>caffe.io.load_image</code>也是用的这个，具体可以在<code>python/caffe/io.py</code>中查看。之后我们也用这个库进行图像的保存。<br>以上的程序较为简单，读取了示例图片，为了验证是否正确又另存为了副本。最后输出的shape为：（360,480,3）。<br><img src="http://img.blog.csdn.net/20161109160018966" alt="cat"></p>
<hr>
<h2 id="载入卷积模型"><a href="#载入卷积模型" class="headerlink" title="载入卷积模型"></a>载入卷积模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">net = caffe.Net(<span class="string">'examples/net_surgery/conv.prototxt'</span>, caffe.TEST)</div></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"># Simple single-layer network to showcase editing model parameters.</div><div class="line">name: <span class="string">"convolution"</span></div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"data"</span></div><div class="line">  type: <span class="string">"Input"</span></div><div class="line">  top: <span class="string">"data"</span></div><div class="line">  input_param &#123; shape: &#123; dim: <span class="number">1</span> dim: <span class="number">3</span> dim: <span class="number">100</span> dim: <span class="number">100</span> &#125; &#125;</div><div class="line">&#125;</div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"conv"</span></div><div class="line">  type: <span class="string">"Convolution"</span></div><div class="line">  bottom: <span class="string">"data"</span></div><div class="line">  top: <span class="string">"conv"</span></div><div class="line">  convolution_param &#123;</div><div class="line">    num_output: <span class="number">16</span></div><div class="line">    kernel_size: <span class="number">5</span></div><div class="line">    stride: <span class="number">1</span></div><div class="line">    weight_filler &#123;</div><div class="line">      type: <span class="string">"gaussian"</span></div><div class="line">      <span class="built_in">std</span>: <span class="number">0.01</span></div><div class="line">    &#125;</div><div class="line">    bias_filler &#123;</div><div class="line">      type: <span class="string">"constant"</span></div><div class="line">      value: <span class="number">0</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>载入的是示例中简单的卷积模型，但在shape上有所修改：第二个dim由1改为3，代表三通道输入；同时num_output改为了16，增加了滤波器的个数。</p>
<hr>
<h2 id="数据格式处理"><a href="#数据格式处理" class="headerlink" title="数据格式处理"></a>数据格式处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">im_input=im[np.newaxis,:,:,:].transpose(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">"data-blobs:"</span>,im_input.shape</div><div class="line"><span class="comment">#print "datashape:",net.blobs['data'].data.shape</span></div><div class="line">net.blobs[<span class="string">'data'</span>].reshape(*im_input.shape)</div><div class="line">net.blobs[<span class="string">'data'</span>].data[...] = im_input</div></pre></td></tr></table></figure>
<p>图片的输入规格和caffe的blob规格并不相同。图片的维度为（360,480,3），而blob的4维数组要求通道数在前，因此需要改变顺序，并且由于仅有一张图片，需要增加一维代表图片序号，该维值为0即可。因此<code>im_input=im[np.newaxis,:,:,:].transpose(0,3,1,2)</code>先增加了一个维度，后改变了维的顺序，使其与输入要求相同。之后改变blobs数据层的维度，使之与图像大小相同（这一步感觉会让网络配置文件中input_param：shape的维度改变，可能是为了方便程序的扩展，没有直接改配置文件）。最后把图像数据输入到blob。</p>
<hr>
<h2 id="保存图像"><a href="#保存图像" class="headerlink" title="保存图像"></a>保存图像</h2><p>为了方便调用，可以写一个保存图片的函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_data</span><span class="params">(data,name,padsize=<span class="number">1</span>, padval=<span class="number">0</span>)</span>:</span></div><div class="line">    data -= data.min()</div><div class="line">    data /= data.max()     </div><div class="line">    <span class="comment"># force the number of filters to be square</span></div><div class="line">    n = int(np.ceil(np.sqrt(data.shape[<span class="number">0</span>])))</div><div class="line">    padding = ((<span class="number">0</span>, n ** <span class="number">2</span> - data.shape[<span class="number">0</span>]), (<span class="number">0</span>, padsize), (<span class="number">0</span>, padsize)) + ((<span class="number">0</span>, <span class="number">0</span>),) * (data.ndim - <span class="number">3</span>)</div><div class="line">    data = np.pad(data, padding, mode=<span class="string">'constant'</span>, constant_values=(padval, padval))</div><div class="line">    <span class="comment"># tile the filters into an image</span></div><div class="line">    data = data.reshape((n, n) + data.shape[<span class="number">1</span>:]).transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>) + tuple(range(<span class="number">4</span>, data.ndim + <span class="number">1</span>)))</div><div class="line">    data = data.reshape((n * data.shape[<span class="number">1</span>], n * data.shape[<span class="number">3</span>]) + data.shape[<span class="number">4</span>:])</div><div class="line">    io.imsave(name,data)</div></pre></td></tr></table></figure></p>
<p>保存图片首先进行了归一化操作，之后为了美观生成一个方形模板，再把图片依次放上去。<br>测试这一段可以看一下原图多通道的每一通道分量：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">save_data(net.blobs[<span class="string">'data'</span>].data[<span class="number">0</span>],<span class="string">'origin images.jpg'</span>)</div></pre></td></tr></table></figure></p>
<p><img src="http://img.blog.csdn.net/20161109165215548" alt="origin images"></p>
<hr>
<h2 id="卷积层输出"><a href="#卷积层输出" class="headerlink" title="卷积层输出"></a>卷积层输出</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">net.forward()</div><div class="line"><span class="keyword">print</span> <span class="string">"data-blobs:"</span>,net.blobs[<span class="string">'data'</span>].data.shape</div><div class="line"><span class="keyword">print</span> <span class="string">"conv-blobs:"</span>,net.blobs[<span class="string">'conv'</span>].data.shape</div><div class="line"><span class="keyword">print</span> <span class="string">"weight-blobs:"</span>,net.params[<span class="string">'conv'</span>][<span class="number">0</span>].data.shape</div><div class="line">save_data(net.params[<span class="string">'conv'</span>][<span class="number">0</span>].data[:,<span class="number">0</span>],<span class="string">'conv weights(filter).jpg'</span>)</div><div class="line">save_data(net.blobs[<span class="string">'conv'</span>].data[<span class="number">0</span>],<span class="string">'post-conv images.jpg'</span>)</div></pre></td></tr></table></figure>
<p>经过一次向前计算，得到了卷积后的结果和初始的卷积核值，打印他们的大小分别为：</p>
<pre><code>data-blobs: (1, 3, 360, 480)
conv-blobs: (1, 16, 356, 476)
weight-blobs: (16, 3, 5, 5)
</code></pre><p>最后保存成了两个图片文件：</p>
<p><div align="center"><br><img src="http://img.blog.csdn.net/20161109170612319" alt="conv weights(filter)"></div></p>
<p><img src="http://img.blog.csdn.net/20161109170554412" alt="post-conv images"></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://joyfyan.github.io/2016/11/08/caffe学习（10）数据转换img2db/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yan Joy">
      <meta itemprop="description" content="Default~">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小一一的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/11/08/caffe学习（10）数据转换img2db/" itemprop="url">
                  caffe学习（10）数据转换img2db
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-11-08 17:12:00" itemprop="dateCreated datePublished" datetime="2016-11-08T17:12:00+08:00">2016-11-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2016-11-18 15:30:50" itemprop="dateModified" datetime="2016-11-18T15:30:50+08:00">2016-11-18</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2016/11/08/caffe学习（10）数据转换img2db/" class="leancloud_visitors" data-flag-title="caffe学习（10）数据转换img2db">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views: </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在处理图像时，我们已拥有的图像往往是常用的jpg、png格式，但在caffe中，输入的数据类型常是lmdb或leveldb，因此我们需要对原始数据进行转换。</p>
<blockquote>
<p><a href="http://www.cnblogs.com/denny402/p/5082341.html" target="_blank" rel="external">Caffe学习系列(11)：图像数据转换成db（leveldb/lmdb)文件</a></p>
</blockquote>
<hr>
<h2 id="convert-imageset"><a href="#convert-imageset" class="headerlink" title="convert_imageset"></a>convert_imageset</h2><p>在caffe中，提供了一个用于格式转换的文件：convert_imageset.cpp，存放在根目录下的tools文件夹下。编译之后，生成对应的可执行文件放在 build/tools/ 下面，这个文件的作用就是用于将图片文件转换成caffe框架中能直接使用的db文件。<br>而windows平台下，如果用vs编译会在build/x64/debug中生成convert_imageset.exe。</p>
<hr>
<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p>该文件的使用格式：</p>
<pre><code>convert_imageset [FLAGS] ROOTFOLDER/ LISTFILE DB_NAME
</code></pre><p>而数据集推荐的是imagenet。对于具体的参数包含有：</p>
<ul>
<li>FLAGS：图片转换参数。</li>
<li>ROOTFOLDER/：图片的绝对路径，从系统根目录开始。</li>
<li>LISTFILE：图片文件清单文件，为txt格式，一行有一张图片。</li>
<li>DB_NAME：生成db文件的存放目录。</li>
</ul>
<p>其中图片文件清单比较麻烦，因此可以使用脚本文件读取图片并保存为txt。</p>
<hr>
<h3 id="图片文件清单的生成"><a href="#图片文件清单的生成" class="headerlink" title="图片文件清单的生成"></a>图片文件清单的生成</h3><p>本文以caffe程序中自带的图片为例，进行讲解，图片目录是  example/images/, 两张图片，一张为cat.jpg, 另一张为fish_bike.jpg，表示两个类别。我们创建一个sh脚本文件，调用linux命令来生成图片清单：</p>
<pre><code># sudo vi examples/images/create_filelist.sh
</code></pre><p>编辑这个文件,输入下面的代码并保存：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># /usr/bin/env sh</span></div><div class="line">DATA=examples/images</div><div class="line"><span class="built_in">echo</span> <span class="string">"Create train.txt..."</span></div><div class="line">rm -rf <span class="variable">$DATA</span>/train.txt</div><div class="line">find <span class="variable">$DATA</span> -name *cat.jpg | cut <span class="_">-d</span> <span class="string">'/'</span> <span class="_">-f</span>3 | sed <span class="string">"s/$/ 1/"</span>&gt;&gt;<span class="variable">$DATA</span>/train.txt</div><div class="line">find <span class="variable">$DATA</span> -name *bike.jpg | cut <span class="_">-d</span> <span class="string">'/'</span> <span class="_">-f</span>3 | sed <span class="string">"s/$/ 2/"</span>&gt;&gt;<span class="variable">$DATA</span>/tmp.txt</div><div class="line">cat <span class="variable">$DATA</span>/tmp.txt&gt;&gt;<span class="variable">$DATA</span>/train.txt</div><div class="line">rm -rf <span class="variable">$DATA</span>/tmp.txt</div><div class="line"><span class="built_in">echo</span> <span class="string">"Done.."</span></div></pre></td></tr></table></figure></p>
<p>这个脚本文件中，用到了rm,find, cut, sed,cat等linux命令。</p>
<ul>
<li>rm: 删除文件</li>
<li>find: 寻找文件</li>
<li>cut: 截取路径</li>
<li>sed: 在每行的最后面加上标注。本例中将找到的<em>cat.jpg文件加入标注为1，找到的</em>bike.jpg文件加入标注为2</li>
<li>cat: 将两个类别合并在一个文件里。</li>
</ul>
<p>最终生成如下的一个train.txt文件：</p>
<pre><code>cat.jpg 1
fish-bike.jpg 2
</code></pre><p>当然，图片很少的时候，手动编写这个列表清单文件就行了。但图片很多的情况，就需要用脚本文件来自动生成了。在以后的实际应用中，还需要生成相应的val.txt和test.txt文件，方法是一样的。<br>生成的这个train.txt文件，就可以作为第三个参数，直接使用了。</p>
<hr>
<h3 id="FLAGS参数设置"><a href="#FLAGS参数设置" class="headerlink" title="FLAGS参数设置"></a>FLAGS参数设置</h3><p>接下来，我们来了解一下FLAGS这个参数组，有些什么内容：</p>
<ul>
<li>gray: 是否以灰度图的方式打开图片。程序调用opencv库中的imread()函数来打开图片，默认为false</li>
<li>shuffle: 是否随机打乱图片顺序。默认为false</li>
<li>backend:需要转换成的db文件格式，可选为leveldb或lmdb,默认为lmdb</li>
<li>resize_width/resize_height: 改变图片的大小。在运行中，要求所有图片的尺寸一致，因此需要改变图片大小。 程序调用opencv库的resize（）函数来对图片放大缩小，默认为0，不改变</li>
<li>check_size: 检查所有的数据是否有相同的尺寸。默认为false,不检查</li>
<li>encoded: 是否将原图片编码放入最终的数据中，默认为false</li>
<li>encode_type: 与前一个参数对应，将图片编码为哪一个格式：‘png’,’jpg’……</li>
</ul>
<p>好了，知道这些参数后，我们就可以调用命令来生成最终的lmdb格式数据了。</p>
<hr>
<h3 id="转换脚本的编写"><a href="#转换脚本的编写" class="headerlink" title="转换脚本的编写"></a>转换脚本的编写</h3><p>由于参数比较多，因此我们可以编写一个sh脚本来执行命令。<br>首先，创建sh脚本文件：</p>
<pre><code># sudo vi examples/images/create_lmdb.sh
</code></pre><p>编辑，输入下面的代码并保存：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/usr/bin/en sh</span></div><div class="line">DATA=examples/images</div><div class="line">rm -rf <span class="variable">$DATA</span>/img_train_lmdb</div><div class="line">build/tools/convert_imageset --shuffle \</div><div class="line">--resize_height=256 --resize_width=256 \</div><div class="line">/home/xxx/caffe/examples/images/ <span class="variable">$DATA</span>/train.txt  <span class="variable">$DATA</span>/img_train_lmdb</div></pre></td></tr></table></figure></p>
<p>设置参数-shuffle,打乱图片顺序。设置参数-resize_height和-resize_width将所有图片尺寸都变为256*256。<br>/home/xxx/caffe/examples/images/ 为图片保存的绝对路径。<br>最后，运行这个脚本文件：</p>
<pre><code># sudo sh examples/images/create_lmdb.sh
</code></pre><p>就会在examples/images/ 目录下生成一个名为 img_train_lmdb的文件夹，里面的文件就是我们需要的db文件了。</p>
<hr>
<p>针对于windows环境，可以使用bat快速运行：</p>
<pre><code>D:/caffe-master/Build/x64/Release/convert_imageset --shuffle --resize_height=256 --resize_width=256 D:/caffe-master/examples/images/ D:/caffe-master/examples/images/train.txt D:/caffe-master/examples/images/img_train_lmdb
</code></pre>
          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://joyfyan.github.io/2016/11/08/caffe学习（9）LeNet在Caffe上的使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yan Joy">
      <meta itemprop="description" content="Default~">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小一一的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/11/08/caffe学习（9）LeNet在Caffe上的使用/" itemprop="url">
                  caffe学习（9）LeNet在Caffe上的使用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-11-08 15:57:00" itemprop="dateCreated datePublished" datetime="2016-11-08T15:57:00+08:00">2016-11-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2016-11-18 15:30:12" itemprop="dateModified" datetime="2016-11-18T15:30:12+08:00">2016-11-18</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2016/11/08/caffe学习（9）LeNet在Caffe上的使用/" class="leancloud_visitors" data-flag-title="caffe学习（9）LeNet在Caffe上的使用">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views: </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>使用官网例程训练LeNet。</p>
<blockquote>
<p><a href="http://caffe.berkeleyvision.org/gathered/examples/mnist.html" target="_blank" rel="external">Training LeNet on MNIST with Caffe</a></p>
</blockquote>
<hr>
<h2 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h2><p>Caffe程序的运行要注意需命令行要在Caffe的根目录下。</p>
<pre><code>cd $CAFFE_ROOT
./data/mnist/get_mnist.sh
./examples/mnist/create_mnist.sh
</code></pre><p>依次运行，会在caffe\examples\mnist下得到两个目录mnist_train_lmdb, 和 mnist_test_lmdb，作为训练和测试集。</p>
<hr>
<h2 id="定义MNIST网络"><a href="#定义MNIST网络" class="headerlink" title="定义MNIST网络"></a>定义MNIST网络</h2><p>Caffe上的LeNet并不是传统的<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" target="_blank" rel="external">LeNet-5</a>，在参数上还是有所不同的。以\caffe\examples\mnist\lenet_train_test.prototxt 为例（本地文件与官网上的教程也有所区别），介绍一下如何定义网络。首先是定义网络名称：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">name: <span class="string">"LeNet"</span></div></pre></td></tr></table></figure></p>
<h3 id="数据层"><a href="#数据层" class="headerlink" title="数据层"></a>数据层</h3><p>利用我们已经生成的MNIST数据，把数据输入到网络：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"mnist"</span></div><div class="line">  type: <span class="string">"Data"</span></div><div class="line">  top: <span class="string">"data"</span></div><div class="line">  top: <span class="string">"label"</span></div><div class="line">  include &#123;</div><div class="line">    phase: TRAIN</div><div class="line">  &#125;</div><div class="line">  transform_param &#123;</div><div class="line">    scale: <span class="number">0.00390625</span></div><div class="line">  &#125;</div><div class="line">  data_param &#123;</div><div class="line">    source: <span class="string">"examples/mnist/mnist_train_lmdb"</span></div><div class="line">    batch_size: <span class="number">64</span></div><div class="line">    backend: LMDB</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"mnist"</span></div><div class="line">  type: <span class="string">"Data"</span></div><div class="line">  top: <span class="string">"data"</span></div><div class="line">  top: <span class="string">"label"</span></div><div class="line">  include &#123;</div><div class="line">    phase: TEST</div><div class="line">  &#125;</div><div class="line">  transform_param &#123;</div><div class="line">    scale: <span class="number">0.00390625</span></div><div class="line">  &#125;</div><div class="line">  data_param &#123;</div><div class="line">    source: <span class="string">"examples/mnist/mnist_test_lmdb"</span></div><div class="line">    batch_size: <span class="number">100</span></div><div class="line">    backend: LMDB</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>具体来说，本层名为：”mnist”，类型为”data”，输出到两个blob：”data””label”。下面用到了之前所说的include，包含TRAIN与TEST，表示该层是在训练还是测试时调用，其区别在于输入的不同数据集（见data_param）。transform_param用于输入数据的缩放，使之在$[0,1]$内，其中$0.00390625=1/256$。</p>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>本网络中，有两个卷积层，第一层为：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"conv1"</span></div><div class="line">  type: <span class="string">"Convolution"</span></div><div class="line">  bottom: <span class="string">"data"</span></div><div class="line">  top: <span class="string">"conv1"</span></div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">1</span></div><div class="line">  &#125;</div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">2</span></div><div class="line">  &#125;</div><div class="line">  convolution_param &#123;</div><div class="line">    num_output: <span class="number">20</span></div><div class="line">    kernel_size: <span class="number">5</span></div><div class="line">    stride: <span class="number">1</span></div><div class="line">    weight_filler &#123;</div><div class="line">      type: <span class="string">"xavier"</span></div><div class="line">    &#125;</div><div class="line">    bias_filler &#123;</div><div class="line">      type: <span class="string">"constant"</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这一层使用数据层的数据作为输入，生成”conv1”层，具体产生20个通道的输出，卷积核大小为5，卷积步长为1。先后两个lr_mults是对本层可学习参数的速率调整，权重学习率与solver中的学习率相同，而偏置学习率为其两倍，这往往导致更好的手链率。权重初始化使用”xavier”方式，偏置初始化为0。<br>第二个卷积层在池化层1后，输出到池化层2，参数除了输出个数（num_output）改为50，其余的相同。</p>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"pool1"</span></div><div class="line">  type: <span class="string">"Pooling"</span></div><div class="line">  bottom: <span class="string">"conv1"</span></div><div class="line">  top: <span class="string">"pool1"</span></div><div class="line">  pooling_param &#123;</div><div class="line">    pool: MAX</div><div class="line">    kernel_size: <span class="number">2</span></div><div class="line">    stride: <span class="number">2</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>第一个池化层表示采用最大池化的方法，进行大小为2，步长为2的非重叠池化。第二个池化层与第一个完全相同，其输入为卷积层2，输出到全连接层1.</p>
<h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"ip1"</span></div><div class="line">  type: <span class="string">"InnerProduct"</span></div><div class="line">  bottom: <span class="string">"pool2"</span></div><div class="line">  top: <span class="string">"ip1"</span></div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">1</span></div><div class="line">  &#125;</div><div class="line">  param &#123;</div><div class="line">    lr_mult: <span class="number">2</span></div><div class="line">  &#125;</div><div class="line">  inner_product_param &#123;</div><div class="line">    num_output: <span class="number">500</span></div><div class="line">    weight_filler &#123;</div><div class="line">      type: <span class="string">"xavier"</span></div><div class="line">    &#125;</div><div class="line">    bias_filler &#123;</div><div class="line">      type: <span class="string">"constant"</span></div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>全连接层与卷积层的写法非常相似，ip1层产生500个输出。<br>在激活层后，还有一个全连接层，用于最后的输出分类，因此有10个输出。</p>
<h3 id="激活层"><a href="#激活层" class="headerlink" title="激活层"></a>激活层</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"relu1"</span></div><div class="line">  type: <span class="string">"ReLU"</span></div><div class="line">  bottom: <span class="string">"ip1"</span></div><div class="line">  top: <span class="string">"ip1"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>ReLU是一个元素操作，因此可以使用原地操作（in-place operations）用于节省空间。其实就是top与bottom的名字相同。当然其他的层不能使用重复的blob名称。</p>
<h3 id="损失层"><a href="#损失层" class="headerlink" title="损失层"></a>损失层</h3><p>最后是损失层：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"loss"</span></div><div class="line">  type: <span class="string">"SoftmaxWithLoss"</span></div><div class="line">  bottom: <span class="string">"ip2"</span></div><div class="line">  bottom: <span class="string">"label"</span></div><div class="line">  top: <span class="string">"loss"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>softmax_loss层同时实现softmax和多项对数损失（这可以节省时间并提高数值稳定性）。输入为预测的输出和label，并且没有输出（向后的输出）。它计算损失函数，并且反向传播相对于ip2的梯度。</p>
<h3 id="Accuracy准确率层"><a href="#Accuracy准确率层" class="headerlink" title="Accuracy准确率层"></a>Accuracy准确率层</h3><p>这一层是用于在测试中返回准确率使用的：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"accuracy"</span></div><div class="line">  type: <span class="string">"Accuracy"</span></div><div class="line">  bottom: <span class="string">"ip2"</span></div><div class="line">  bottom: <span class="string">"label"</span></div><div class="line">  top: <span class="string">"accuracy"</span></div><div class="line">  include &#123;</div><div class="line">    phase: TEST</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>与loss相似，但要注明<code>phase: TEST</code>。</p>
<hr>
<h2 id="定义MNIST-求解器"><a href="#定义MNIST-求解器" class="headerlink" title="定义MNIST 求解器"></a>定义MNIST 求解器</h2><p>求解器文件路径为：</p>
<pre><code>$CAFFE_ROOT/examples/mnist/lenet_solver.prototxt:
</code></pre><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"># The train/test net protocol buffer definition</div><div class="line">net: <span class="string">"examples/mnist/lenet_train_test.prototxt"</span></div><div class="line"># test_iter specifies how many forward passes the test should carry out.</div><div class="line"># In the <span class="keyword">case</span> of MNIST, we have test batch size <span class="number">100</span> and <span class="number">100</span> test iterations,</div><div class="line"><span class="meta"># covering the full 10,000 testing images.</span></div><div class="line">test_iter: <span class="number">100</span></div><div class="line"># Carry out testing every <span class="number">500</span> training iterations.</div><div class="line">test_interval: <span class="number">500</span></div><div class="line"># The base learning rate, momentum and the weight decay of the network.</div><div class="line">base_lr: <span class="number">0.01</span></div><div class="line">momentum: <span class="number">0.9</span></div><div class="line">weight_decay: <span class="number">0.0005</span></div><div class="line"># The learning rate policy</div><div class="line">lr_policy: <span class="string">"inv"</span></div><div class="line">gamma: <span class="number">0.0001</span></div><div class="line">power: <span class="number">0.75</span></div><div class="line"># Display every <span class="number">100</span> iterations</div><div class="line">display: <span class="number">100</span></div><div class="line"># The maximum number of iterations</div><div class="line">max_iter: <span class="number">10000</span></div><div class="line"><span class="meta"># snapshot intermediate results</span></div><div class="line">snapshot: <span class="number">5000</span></div><div class="line">snapshot_prefix: <span class="string">"examples/mnist/lenet"</span></div><div class="line"><span class="meta"># solver mode: CPU or GPU</span></div><div class="line">solver_mode: GPU</div></pre></td></tr></table></figure>
<p>这些参数见上一篇：<a href="http://blog.csdn.net/yan_joy/article/details/53079185" target="_blank" rel="external">caffe学习（8）Solver 配置详解</a>。</p>
<hr>
<h2 id="训练并测试模型"><a href="#训练并测试模型" class="headerlink" title="训练并测试模型"></a>训练并测试模型</h2><p>简单的话可以直接运行：</p>
<pre><code>cd $CAFFE_ROOT
./examples/mnist/train_lenet.sh
</code></pre><p>即运行：</p>
<pre><code>./build/tools/caffe train --solver=examples/mnist/lenet_solver.prototxt
</code></pre><p>也就是我们上面的求解器配置文件。<br>首先出现的是我们打开的solver文件，之后打开网络模型：lenet_train_test.prototxt，初始化网络参数。</p>
<pre><code>I1108 16:08:29.103813 46285 layer_factory.hpp:77] Creating layer mnist
I1108 16:08:29.104310 46285 net.cpp:100] Creating Layer mnist
I1108 16:08:29.104336 46285 net.cpp:408] mnist -&gt; data
I1108 16:08:29.104374 46285 net.cpp:408] mnist -&gt; label
I1108 16:08:29.107558 46328 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
</code></pre><p>不过仔细看的话会发现初始化了两遍网络，其实是因为我们同时在训练和测试，这两个网络的区别就是测试有”accuracy”层，训练没有。这些信息告诉了层之间的连接、输入、输出关系。结束后正式开始训练：</p>
<pre><code>I1108 16:08:29.156116 46285 net.cpp:283] Network initialization done.
I1108 16:08:29.156206 46285 solver.cpp:60] Solver scaffolding done.
I1108 16:08:29.156466 46285 caffe.cpp:251] Starting Optimization
I1108 16:08:29.156500 46285 solver.cpp:279] Solving LeNet
I1108 16:08:29.156512 46285 solver.cpp:280] Learning Rate Policy: inv
I1108 16:08:29.158172 46285 solver.cpp:337] Iteration 0, Testing net (#0)
I1108 16:08:31.021287 46285 solver.cpp:404]     Test net output #0: accuracy = 0.0933
I1108 16:08:31.021385 46285 solver.cpp:404]     Test net output #1: loss = 2.36349 (* 1 = 2.36349 loss)
</code></pre><p>可以看到，初始化参数后测试模型，准确率有9.33%，比10%还低一些。基于参数设置，我们每迭代100次输出loss 信息，每迭代500次测试模型，输出accuracy 信息：</p>
<pre><code>I1108 16:08:46.974346 46285 solver.cpp:337] Iteration 500, Testing net (#0)
I1108 16:08:48.808943 46285 solver.cpp:404]     Test net output #0: accuracy = 0.9767
I1108 16:08:48.809048 46285 solver.cpp:404]     Test net output #1: loss = 0.068445 (* 1 = 0.068445 loss)
I1108 16:08:48.823623 46285 solver.cpp:228] Iteration 500, loss = 0.0609579
I1108 16:08:48.823714 46285 solver.cpp:244]     Train net output #0: loss = 0.0609579 (* 1 = 0.0609579 loss)
I1108 16:08:48.823740 46285 sgd_solver.cpp:106] Iteration 500, lr = 0.0192814
</code></pre><p>可以发现输出500次后准确率已经达到了97.67%。<br>达到训练次数后（这里减少了训练次数），得到最终结果：</p>
<pre><code>I1108 16:09:04.727638 46285 solver.cpp:454] Snapshotting to binary proto file examples/mnist/lenet_iter_1000.caffemodel
I1108 16:09:04.754024 46285 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_1000.solverstate
I1108 16:09:04.770093 46285 solver.cpp:317] Iteration 1000, loss = 0.0819535
I1108 16:09:04.770177 46285 solver.cpp:337] Iteration 1000, Testing net (#0)
I1108 16:09:06.607952 46285 solver.cpp:404]     Test net output #0: accuracy = 0.9844
I1108 16:09:06.608042 46285 solver.cpp:404]     Test net output #1: loss = 0.0491373 (* 1 = 0.0491373 loss)
I1108 16:09:06.608055 46285 solver.cpp:322] Optimization Done.
I1108 16:09:06.608064 46285 caffe.cpp:254] Optimization Done.
</code></pre><p>得到了两个文件：lenet_iter_1000.caffemodel和lenet_iter_1000.solverstate。</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://joyfyan.github.io/2016/11/08/caffe学习（8）Solver 配置详解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yan Joy">
      <meta itemprop="description" content="Default~">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小一一的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/11/08/caffe学习（8）Solver 配置详解/" itemprop="url">
                  caffe学习（8）Solver 配置详解
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-11-08 09:45:00" itemprop="dateCreated datePublished" datetime="2016-11-08T09:45:00+08:00">2016-11-08</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2016-11-18 15:29:24" itemprop="dateModified" datetime="2016-11-18T15:29:24+08:00">2016-11-18</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2016/11/08/caffe学习（8）Solver 配置详解/" class="leancloud_visitors" data-flag-title="caffe学习（8）Solver 配置详解">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views: </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Solver是求解学习模型的核心配置文件，网络确定后，solver就决定了学习的效果。本文结合caffe.proto和网上资料，对solver配置进行学习。</p>
<blockquote>
<p><a href="http://caffe.berkeleyvision.org/tutorial/solver.html" target="_blank" rel="external">Solver</a><br><a href="http://www.cnblogs.com/denny402/p/5074049.html" target="_blank" rel="external">Caffe学习系列(7)：solver及其配置，denny402</a></p>
</blockquote>
<hr>
<h2 id="Solver在caffe中的定义"><a href="#Solver在caffe中的定义" class="headerlink" title="Solver在caffe中的定义"></a>Solver在caffe中的定义</h2><p>通常的solver文件与net文件相互关联，同样的net我们往往使用不同的solver尝试得到最好的效果，其运行代码为：</p>
<pre><code>caffe train --solver=*_slover.prototxt
</code></pre><p>关于solver的一切，都在caffe.proto文件中message SolverParameter 这一部分。</p>
<p><strong>网络文件源</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Proto filename for the train net, possibly combined with one or more</span></div><div class="line"><span class="comment">// test nets.</span></div><div class="line">optional <span class="built_in">string</span> net = <span class="number">24</span>;</div><div class="line"><span class="comment">// Inline train net param, possibly combined with one or more test nets.</span></div><div class="line">optional NetParameter net_param = <span class="number">25</span>;</div><div class="line"></div><div class="line">optional <span class="built_in">string</span> train_net = <span class="number">1</span>; <span class="comment">// Proto filename for the train net.</span></div><div class="line">repeated <span class="built_in">string</span> test_net = <span class="number">2</span>; <span class="comment">// Proto filenames for the test nets.</span></div><div class="line">optional NetParameter train_net_param = <span class="number">21</span>; <span class="comment">// Inline train net params.</span></div><div class="line">repeated NetParameter test_net_param = <span class="number">22</span>; <span class="comment">// Inline test net params.</span></div></pre></td></tr></table></figure></p>
<p>这是最开始的部分，需要说明net文件的位置。在这四个train_net_param, train_net, net_param, net字段中至少需要出现一个，当出现多个时，就会按着(1) test_net_param, (2) test_net, (3) net_param/net 的顺序依次求解。必须为每个test_net指定一个test_iter。还可以为每个test_net指定test_level和/或test_stage。注意的是：文件的路径要从caffe的根目录开始，其它的所有配置都是这样。<br>可以看到这几行的标签序号并不是顺序的，也说明caffe在不断地修改，下一个可用的序号是41。</p>
<p><strong>网络状态</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// The states for the train/test nets. Must be unspecified or</span></div><div class="line"><span class="comment">// specified once per net.</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// By default, all states will have solver = true;</span></div><div class="line"><span class="comment">// train_state will have phase = TRAIN,</span></div><div class="line"><span class="comment">// and all test_state's will have phase = TEST.</span></div><div class="line"><span class="comment">// Other defaults are set according to the NetState defaults.</span></div><div class="line">optional NetState train_state = <span class="number">26</span>;</div><div class="line">repeated NetState test_state = <span class="number">27</span>;</div></pre></td></tr></table></figure></p>
<p>网络状态必须是未指定的或者只能在一个网络中指定一次。<br>关于NetState，其定义为：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">message NetState &#123;</div><div class="line">  optional Phase phase = <span class="number">1</span> [<span class="keyword">default</span> = TEST];</div><div class="line">  optional int32 level = <span class="number">2</span> [<span class="keyword">default</span> = <span class="number">0</span>];</div><div class="line">  repeated <span class="built_in">string</span> stage = <span class="number">3</span>;</div><div class="line">&#125;</div><div class="line"><span class="keyword">enum</span> Phase &#123;</div><div class="line">   TRAIN = <span class="number">0</span>;</div><div class="line">   TEST = <span class="number">1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>迭代器</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// The number of iterations for each test net.</span></div><div class="line">repeated int32 test_iter = <span class="number">3</span>;</div></pre></td></tr></table></figure></p>
<p>首先是<code>test_iter</code>，这需要与test layer中的batch_size结合起来理解。mnist数据中测试样本总数为10000，一次性执行全部数据效率很低，因此我们将测试数据分成几个批次来执行，每个批次的数量就是batch_size。假设我们设置batch_size为100，则需要迭代100次才能将10000个数据全部执行完。因此test_iter设置为100。执行完一次全部数据，称之为一个epoch。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// The number of iterations between two testing phases.</span></div><div class="line">optional int32 test_interval = <span class="number">4</span> [<span class="keyword">default</span> = <span class="number">0</span>];</div><div class="line">optional <span class="keyword">bool</span> test_compute_loss = <span class="number">19</span> [<span class="keyword">default</span> = <span class="literal">false</span>];</div><div class="line"><span class="comment">// If true, run an initial test pass before the first iteration,</span></div><div class="line"><span class="comment">// ensuring memory availability and printing the starting value of the loss.</span></div><div class="line">optional <span class="keyword">bool</span> test_initialization = <span class="number">32</span> [<span class="keyword">default</span> = <span class="literal">true</span>];</div></pre></td></tr></table></figure></p>
<p><code>test_interval</code>是指测试间隔，每训练test_interval次，进行一次测试。同时<code>test_compute_loss</code>可以选择是否计算loss。<code>test_initialization</code>是指在第一次迭代前，计算初始的loss以确保内存可用。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">optional <span class="keyword">float</span> base_lr = <span class="number">5</span>; <span class="comment">// The base learning rate</span></div><div class="line"><span class="comment">// the number of iterations between displaying info. If display = 0, no info</span></div><div class="line"><span class="comment">// will be displayed.</span></div><div class="line">optional int32 display = <span class="number">6</span>;</div><div class="line"><span class="comment">// Display the loss averaged over the last average_loss iterations</span></div><div class="line">optional int32 average_loss = <span class="number">33</span> [<span class="keyword">default</span> = <span class="number">1</span>];</div><div class="line">optional int32 max_iter = <span class="number">7</span>; <span class="comment">// the maximum number of iterations</span></div><div class="line"><span class="comment">// accumulate gradients over `iter_size` x `batch_size` instances</span></div><div class="line">optional int32 iter_size = <span class="number">36</span> [<span class="keyword">default</span> = <span class="number">1</span>];</div></pre></td></tr></table></figure>
<p><code>base_lr</code>指基础的学习率；<code>display</code>是信息显示间隔，迭代一定次数显示一次信息。<code>average_loss</code>用于显示在上次average_loss迭代中的平均损失。<code>max_iter</code>是最大迭代次数，需要合适设置达到精度、震荡的平衡。<code>iter_size</code>是迭代器大小，梯度的计算是通过<code>iter_size</code> x <code>batch_size</code>决定的。</p>
<p><strong>学习策略</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">optional <span class="built_in">string</span> lr_policy = <span class="number">8</span>;</div><div class="line">optional <span class="keyword">float</span> gamma = <span class="number">9</span>; <span class="comment">// The parameter to compute the learning rate.</span></div><div class="line">optional <span class="keyword">float</span> power = <span class="number">10</span>; <span class="comment">// The parameter to compute the learning rate.</span></div><div class="line">optional <span class="keyword">float</span> momentum = <span class="number">11</span>; <span class="comment">// The momentum value.</span></div><div class="line">optional <span class="keyword">float</span> weight_decay = <span class="number">12</span>; <span class="comment">// The weight decay.</span></div><div class="line"><span class="comment">// regularization types supported: L1 and L2</span></div><div class="line"><span class="comment">// controlled by weight_decay</span></div><div class="line">optional <span class="built_in">string</span> regularization_type = <span class="number">29</span> [<span class="keyword">default</span> = <span class="string">"L2"</span>];</div><div class="line"><span class="comment">// the stepsize for learning rate policy "step"</span></div><div class="line">optional int32 stepsize = <span class="number">13</span>;</div><div class="line"><span class="comment">// the stepsize for learning rate policy "multistep"</span></div><div class="line">repeated int32 stepvalue = <span class="number">34</span>;</div></pre></td></tr></table></figure>
<p>只要是梯度下降法来求解优化，都会有一个学习率，也叫步长。base_lr用于设置基础学习率，在迭代的过程中，可以对基础学习率进行调整。怎么样进行调整，就是调整的策略，由lr_policy来设置。caffe提供了多种policy：</p>
<ul>
<li>fixed: 总是返回base_lr（学习率不变）</li>
<li>step: 返回 base_lr * gamma ^ (floor(iter / step))<br>还需要设置stepsize参数以确定step，iter表示当前迭代次数。</li>
<li>exp: 返回base_lr * gamma ^ iter， iter为当前迭代次数</li>
<li>inv: 如果设置为inv,还需要设置一个power, 返回base_lr <em> (1 + gamma </em> iter) ^ (- power)</li>
<li>multistep: 如果设置为multistep,则还需要设置一个stepvalue。这个参数和step很相似，step是均匀等间隔变化，而multistep则是根据stepvalue值变化。</li>
<li>poly: 学习率进行多项式误差, 返回 base_lr (1 - iter/max_iter) ^ (power)</li>
<li>sigmoid: 学习率进行sigmod衰减，返回 base_lr ( 1/(1 + exp(-gamma * (iter - stepsize))))。</li>
</ul>
<p>multistep示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">base_lr: <span class="number">0.01</span></div><div class="line">momentum: <span class="number">0.9</span></div><div class="line">weight_decay: <span class="number">0.0005</span></div><div class="line"><span class="comment"># The learning rate policy</span></div><div class="line">lr_policy: <span class="string">"multistep"</span></div><div class="line">gamma: <span class="number">0.9</span></div><div class="line">stepvalue: <span class="number">5000</span></div><div class="line">stepvalue: <span class="number">7000</span></div><div class="line">stepvalue: <span class="number">8000</span></div><div class="line">stepvalue: <span class="number">9000</span></div><div class="line">stepvalue: <span class="number">9500</span></div></pre></td></tr></table></figure></p>
<p>之后有<code>momentum</code>，上次梯度更新的权重；<code>weight_decay</code>权重衰减，防止过拟合；<code>regularization_type</code>正则化方式。</p>
<p><strong>clip_gradients</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">optional <span class="keyword">float</span> clip_gradients = <span class="number">35</span> [<span class="keyword">default</span> = <span class="number">-1</span>];</div></pre></td></tr></table></figure></p>
<p>参数梯度的实际L2范数较大时，将clip_gradients设置为&gt; = 0，以将参数梯度剪切到该L2范数。具体作用还不是很理解。</p>
<p><strong>snapshot快照</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">optional int32 snapshot = <span class="number">14</span> [<span class="keyword">default</span> = <span class="number">0</span>]; <span class="comment">// The snapshot interval</span></div><div class="line">optional <span class="built_in">string</span> snapshot_prefix = <span class="number">15</span>; <span class="comment">// The prefix for the snapshot.</span></div><div class="line"><span class="comment">// whether to snapshot diff in the results or not. Snapshotting diff will help</span></div><div class="line"><span class="comment">// debugging but the final protocol buffer size will be much larger.</span></div><div class="line">optional <span class="keyword">bool</span> snapshot_diff = <span class="number">16</span> [<span class="keyword">default</span> = <span class="literal">false</span>];</div><div class="line"><span class="keyword">enum</span> SnapshotFormat &#123;</div><div class="line">  HDF5 = <span class="number">0</span>;</div><div class="line">  BINARYPROTO = <span class="number">1</span>;</div><div class="line">&#125;</div><div class="line">optional SnapshotFormat snapshot_format = <span class="number">37</span> [<span class="keyword">default</span> = BINARYPROTO];</div></pre></td></tr></table></figure></p>
<p>快照可以将训练出来的model和solver状态进行保存，<code>snapshot</code>用于设置训练多少次后进行保存，默认为0，不保存。<code>snapshot_prefix</code>设置保存路径。还可以设置<code>snapshot_diff</code>，是否保存梯度值，保存有利于调试，但需要较大空间存储，默认为false，不保存。也可以设置<code>snapshot_format</code>，保存的类型。有两种选择：HDF5 和BINARYPROTO ，默认为BINARYPROTO。</p>
<p><strong>运行模式</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">enum</span> SolverMode &#123;</div><div class="line">  CPU = <span class="number">0</span>;</div><div class="line">  GPU = <span class="number">1</span>;</div><div class="line">&#125;</div><div class="line">optional SolverMode solver_mode = <span class="number">17</span> [<span class="keyword">default</span> = GPU];</div><div class="line"><span class="comment">// the device_id will that be used in GPU mode. Use device_id = 0 in default.</span></div><div class="line">optional int32 device_id = <span class="number">18</span> [<span class="keyword">default</span> = <span class="number">0</span>];</div><div class="line"><span class="comment">// If non-negative, the seed with which the Solver will initialize the Caffe</span></div><div class="line"><span class="comment">// random number generator -- useful for reproducible results. Otherwise,</span></div><div class="line"><span class="comment">// (and by default) initialize using a seed derived from the system clock.</span></div><div class="line">optional int64 random_seed = <span class="number">20</span> [<span class="keyword">default</span> = <span class="number">-1</span>];</div></pre></td></tr></table></figure>
<p>设置CPU或GPU模式，在GPU下还可以指定使用哪一块GPU运行。<code>random_seed</code>用于初始生成随机数种子。</p>
<p><strong>Solver类型</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// type of the solver</span></div><div class="line">optional <span class="built_in">string</span> type = <span class="number">40</span> [<span class="keyword">default</span> = <span class="string">"SGD"</span>];</div><div class="line"></div><div class="line"><span class="comment">// numerical stability for RMSProp, AdaGrad and AdaDelta and Adam</span></div><div class="line">optional <span class="keyword">float</span> delta = <span class="number">31</span> [<span class="keyword">default</span> = <span class="number">1e-8</span>];</div><div class="line"><span class="comment">// parameters for the Adam solver</span></div><div class="line">optional <span class="keyword">float</span> momentum2 = <span class="number">39</span> [<span class="keyword">default</span> = <span class="number">0.999</span>];</div><div class="line"></div><div class="line"><span class="comment">// RMSProp decay value</span></div><div class="line"><span class="comment">// MeanSquare(t) = rms_decay*MeanSquare(t-1) + (1-rms_decay)*SquareGradient(t)</span></div><div class="line">optional <span class="keyword">float</span> rms_decay = <span class="number">38</span>;</div></pre></td></tr></table></figure>
<p><code>type</code>是solver的类型，目前有SGD、NESTEROV、ADAGRAD、RMSPROP、ADADELTA、ADAM = 5这六类。之后的一些是这些类型的特有参数，根据需要设置。</p>
<p><strong>杂项</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// If true, print information about the state of the net that may help with</span></div><div class="line"><span class="comment">// debugging learning problems.</span></div><div class="line">optional <span class="keyword">bool</span> debug_info = <span class="number">23</span> [<span class="keyword">default</span> = <span class="literal">false</span>];</div><div class="line"></div><div class="line"><span class="comment">// If false, don't save a snapshot after training finishes.</span></div><div class="line">optional <span class="keyword">bool</span> snapshot_after_train = <span class="number">28</span> [<span class="keyword">default</span> = <span class="literal">true</span>];</div></pre></td></tr></table></figure>
<p><code>debug_info</code>用于输出调试信息。<code>snapshot_after_train</code>用于训练后是否输出快照。</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://joyfyan.github.io/2016/11/07/Google Protocol Buffer 学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yan Joy">
      <meta itemprop="description" content="Default~">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小一一的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/11/07/Google Protocol Buffer 学习/" itemprop="url">
                  Google Protocol Buffer 学习
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-11-07 20:27:00" itemprop="dateCreated datePublished" datetime="2016-11-07T20:27:00+08:00">2016-11-07</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2016-11-18 15:50:04" itemprop="dateModified" datetime="2016-11-18T15:50:04+08:00">2016-11-18</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/学习/" itemprop="url" rel="index"><span itemprop="name">学习</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2016/11/07/Google Protocol Buffer 学习/" class="leancloud_visitors" data-flag-title="Google Protocol Buffer 学习">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views: </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Caffe上有很多使用了Google Protocol Buffer的东西，从网上来看，这“是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，很适合做数据存储或 RPC 数据交换格式。它可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式”。作为caffe模型定义的数据格式，看懂caffe.proto对caffe的理解会有很大帮助。</p>
<blockquote>
<p><a href="https://developers.google.com/protocol-buffers/docs/overview" target="_blank" rel="external">Google Protobuf</a><br><a href="http://www.ibm.com/developerworks/cn/linux/l-cn-gpb/#ibm-pcon" target="_blank" rel="external">Google Protocol Buffer 的使用和原理，刘 明</a></p>
</blockquote>
<hr>
<h3 id="小例子"><a href="#小例子" class="headerlink" title="小例子"></a>小例子</h3><p>我们首先要在.proto文件中定义协议缓冲区消息类型（protocol buffer message types），来指定要序列化的信息的结构。下面是官网的一个小例子，定义了一个人的信息：</p>
<pre><code>message Person {
  required string name = 1;
  required int32 id = 2;
  optional string email = 3;

  enum PhoneType {
    MOBILE = 0;
    HOME = 1;
    WORK = 2;
  }

  message PhoneNumber {
    required string number = 1;
    optional PhoneType type = 2 [default = HOME];
  }

  repeated PhoneNumber phone = 4;
}
</code></pre><p>在 protobuf 的术语中，结构化数据被称为 Message，message中有不同成员。proto 文件非常类似 java 或者 C 语言的数据定义，<code>string</code>、<code>int32</code>这种类型我们已经见得多了。支持类型包括数字（整数或浮点）, 布尔值,，字符串，原始字节（raw bytes），或者是其他的message类型 (如上例) 。除了这些类型，其前后多了一些“修饰”。类型前是field rules，有可选（<code>optional</code>）、必填（<code>required</code>）、重复（<code>repeated</code>）三种。后面是message中的ID，同一message下ID随成员递增。</p>
<hr>
<h3 id="定义一个消息类型"><a href="#定义一个消息类型" class="headerlink" title="定义一个消息类型"></a>定义一个消息类型</h3><p>上面的例子其实已经定义了一个较为复杂的message。而对于一个完整的proto文件，在文件前还应该加上</p>
<pre><code>syntax = &quot;proto2&quot;;//说明语法是2还是3
package caffe;    //包名，通常与文件名相同
</code></pre><p>首先是field rules，</p>
<p><strong>Specifying Field Rules</strong></p>
<ul>
<li>required：本字段一个massage必须只有一个。</li>
<li>optional：本字段可以有0个或1个。</li>
<li>repeated：本字段可以重复任何次，并保留顺序。</li>
</ul>
<p>其中必填字段在使用中需要小心，特别是从必填改到可选时，读取时可能认为这个字段是不完整的。</p>
<p><strong>Assigning Tags</strong></p>
<p>定义消息中的每一个字段都有唯一的编号标签ID，用于消息二进制标识，并且在使用后不应该变。由于编码的原因，值在1到15范围的编号需要一个字节编码，包括标识号与字段类型。在16到2047范围的标签用两个字节。这对于数据储存大小有很大的联系，因此频繁出现的标签成员应该使编号尽可能小。其原因在于一种Varint的编码。其标签范围是1到$2^{29}-1$（536,870,911），同时除了中间的19000到19999，这是为协议缓冲区（Protocol Buffers）实现保留的。</p>
<p><strong>Reserved Fields</strong></p>
<p>保留字段，是对于被删除或者注释的字段进行保留， 如果以后加载相同.proto的旧版本，这可能会导致严重的问题。确保不会发生这种情况的一种方法是指定保留已删除字段的字段标签。协议缓冲区编译器将报告任何未来的用户是否尝试使用这些字段标识符。</p>
<pre><code>message Foo {
  reserved 2, 15, 9 to 11;
  reserved &quot;foo&quot;, &quot;bar&quot;;
}
</code></pre><p>不能在同一保留语句中混合字段名和标识号。</p>
<hr>
<h3 id="编译-proto文件"><a href="#编译-proto文件" class="headerlink" title="编译.proto文件"></a>编译.proto文件</h3><p>使用写好的proto就可以用编译器将文件编译为目标语言了。在<a href="https://github.com/google/protobuf/releases/tag/v3.0.0" target="_blank" rel="external">protobuf V3.0</a>网站上可以下载 Protobuf V3.0的源代码，<a href="https://github.com/google/protobuf/releases?after=v3.0.0-alpha-3" target="_blank" rel="external">V2.6版本</a>在网页上比较靠后，更新到2.6.1。然后解压编译安装便可以使用它了。从caffe文件上看用的还是2的语法。2和3的区别可以从网上搜到，如<a href="http://www.tuicool.com/articles/YNni6rv" target="_blank" rel="external">Google Protobuf 3版本介绍</a>。其实变化也是不少，比如只保留repeated标记数组类型，optional和required都被去掉了；字段default标记不能使用了。</p>
<p>坑爹的是服务器没有权限装不了，于是只好在自家电脑上用windows版的。主要是用于验证，</p>
<pre><code>package lm; 
message helloworld 
{ 
   required int32     id = 1;   // ID 
   required string    str = 2;  // str 
   optional int32     opt = 3;  //optional field 
}
</code></pre><p>用命令行执行</p>
<pre><code>protoc -I=. --cpp_out=. lm.helloworld.proto
</code></pre><p>得到了两个文件：lm.helloworld.pb.h ， 定义了 C++ 类的头文件<br>lm.helloworld.pb.cc ， C++ 类的实现文件。有了这两个文件，之后我们想读写都可以用类操作实现了。</p>
<hr>
<h3 id="读写数据"><a href="#读写数据" class="headerlink" title="读写数据"></a>读写数据</h3><p><strong>数据写到磁盘代码</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"> <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"lm.helloworld.pb.h"</span></span></div><div class="line">…</div><div class="line"></div><div class="line"> <span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span> </span></div><div class="line"> &#123; </div><div class="line">  </div><div class="line">  lm::helloworld msg1; </div><div class="line">  msg1.set_id(<span class="number">101</span>); </div><div class="line">  msg1.set_str(“hello”); </div><div class="line">    </div><div class="line">  <span class="comment">// Write the new address book back to disk. </span></div><div class="line">  <span class="function">fstream <span class="title">output</span><span class="params">(<span class="string">"./log"</span>, ios::out | ios::trunc | ios::binary)</span></span>; </div><div class="line">        </div><div class="line">  <span class="keyword">if</span> (!msg1.SerializeToOstream(&amp;output)) &#123; </div><div class="line">      <span class="built_in">cerr</span> &lt;&lt; <span class="string">"Failed to write msg."</span> &lt;&lt; <span class="built_in">endl</span>; </div><div class="line">      <span class="keyword">return</span> <span class="number">-1</span>; </div><div class="line">  &#125;         </div><div class="line">  <span class="keyword">return</span> <span class="number">0</span>; </div><div class="line"> &#125;</div></pre></td></tr></table></figure></p>
<p>在代码中，其实重要的只是前三行，定义了helloworld类的对象，设置id的值，设置str的值。最后用SerializeToOstream输出到文件流。</p>
<p><strong>读取数据代码</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"> <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"lm.helloworld.pb.h"</span> </span></div><div class="line">…</div><div class="line"> <span class="function"><span class="keyword">void</span> <span class="title">ListMsg</span><span class="params">(<span class="keyword">const</span> lm::helloworld &amp; msg)</span> </span>&#123; </div><div class="line">  <span class="built_in">cout</span> &lt;&lt; msg.id() &lt;&lt; <span class="built_in">endl</span>; </div><div class="line">  <span class="built_in">cout</span> &lt;&lt; msg.str() &lt;&lt; <span class="built_in">endl</span>; </div><div class="line"> &#125; </div><div class="line"> </div><div class="line"> <span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>* argv[])</span> </span>&#123; </div><div class="line"></div><div class="line">  lm::helloworld msg1; </div><div class="line"> </div><div class="line">  &#123; </div><div class="line">    <span class="function">fstream <span class="title">input</span><span class="params">(<span class="string">"./log"</span>, ios::in | ios::binary)</span></span>; </div><div class="line">    <span class="keyword">if</span> (!msg1.ParseFromIstream(&amp;input)) &#123; </div><div class="line">      <span class="built_in">cerr</span> &lt;&lt; <span class="string">"Failed to parse address book."</span> &lt;&lt; <span class="built_in">endl</span>; </div><div class="line">      <span class="keyword">return</span> <span class="number">-1</span>; </div><div class="line">    &#125; </div><div class="line">  &#125; </div><div class="line"> </div><div class="line">  ListMsg(msg1); </div><div class="line">  … </div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<p>在读取代码中，声明类 helloworld 的对象 msg1，然后利用 ParseFromIstream 从一个 fstream 流中读取信息并反序列化。此后，ListMsg 中采用 get 方法读取消息的内部信息，并进行打印输出操作。</p>
<p>分别运行后得到如下结果：</p>
<pre><code>&gt;writer 
&gt;reader 
101 
Hello
</code></pre><p>验证了程序。</p>
<h3 id="Peotocol-Buffer-编码"><a href="#Peotocol-Buffer-编码" class="headerlink" title="Peotocol Buffer 编码"></a>Peotocol Buffer 编码</h3><p>在标签中说到了Varint，现在再结合编码讲一下，主要是参考了引用2的网页。Varint 中的每个 byte 的最高位 bit 有特殊的含义，如果该位为 1，表示后续的 byte 也是该数字的一部分，如果该位为 0，则结束。其他的 7 个 bit 都用来表示数字。因此小于 128 的数字都可以用一个 byte 表示。大于 128 的数字，比如 300，会用两个字节来表示：1010 1100 0000 0010。下图演示了 Google Protocol Buffer 如何解析两个 bytes。注意到最终计算前将两个 byte 的位置相互交换过一次，这是因为 Google Protocol Buffer 字节序采用 little-endian(小端在前) 的方式。<br><img src="http://img.blog.csdn.net/20161107214645660" alt="Varint编码"><br>消息经过序列化后会成为一个二进制数据流，该流中的数据为一系列的 Key-Value 对。如下图所示：<br><img src="http://img.blog.csdn.net/20161107214939796" alt="message buffer"><br>采用这种 Key-Pair 结构无需使用分隔符来分割不同的 Field。对于可选的 Field，如果消息中不存在该 field，那么在最终的 Message Buffer 中就没有该 field，这些特性都有助于节约消息本身的大小。<br>假如生成如下的消息：</p>
<pre><code>Test1.id = 10; 
Test1.str = “hello”；
</code></pre><p>则最终的 Message Buffer 中有两个 Key-Value 对，一个对应消息中的 id；另一个对应 str。Key 用来标识具体的 field，在解包的时候，Protocol Buffer 根据 Key 就可以知道相应的 Value 应该对应于消息中的哪一个 field。Key 的定义如下：</p>
<pre><code>(field_number &lt;&lt; 3) | wire_type   //&lt;&lt;是左移运算
</code></pre><p>可以看到 Key 由两部分组成。第一部分是 field_number，比如消息 lm.helloworld 中 field id 的 field_number 为 1。第二部分为 wire_type。表示 Value 的传输类型。其中wire_type有如下几种：<br><img src="http://img.blog.csdn.net/20161107215439475" alt="wire type"><br>在我们的例子当中，field id 所采用的数据类型为 int32，因此对应的 wire type 为 0。细心的读者或许会看到在 Type 0 所能表示的数据类型中有 int32 和 sint32 这两个非常类似的数据类型。Google Protocol Buffer 区别它们的主要意图也是为了减少 encoding 后的字节数。<br>在计算机内，一个负数一般会被表示为一个很大的整数，因为计算机定义负数的符号位为数字的最高位。如果采用 Varint 表示一个负数，那么一定需要 5 个 byte。为此 Google Protocol Buffer 定义了 sint32 这种类型，采用 zigzag 编码。Zigzag 编码用无符号数来表示有符号数字，正数和负数交错，这就是 zigzag 这个词的含义了。具体编码如图所示：<br><img src="http://img.blog.csdn.net/20161107215628757" alt="zigza"><br>使用 zigzag 编码，绝对值小的数字，无论正负都可以采用较少的 byte 来表示，充分利用了 Varint 这种技术。<br>其他的数据类型，比如字符串等则采用类似数据库中的 varchar 的表示方法，即用一个 varint 表示长度，然后将其余部分紧跟在这个长度部分之后即可。<br>总之，Protocol Buffer的编码确费尽心机，效果当然也不错，特别是与常用的XML相比，包括解包的速度。</p>
<hr>
<p>了解了一下Google Protocol Buffer，算是一些课外知识了。</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://joyfyan.github.io/2016/11/07/caffe学习（7）损失层、通用层/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yan Joy">
      <meta itemprop="description" content="Default~">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小一一的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/11/07/caffe学习（7）损失层、通用层/" itemprop="url">
                  caffe学习（7）损失层、通用层
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-11-07 16:19:00" itemprop="dateCreated datePublished" datetime="2016-11-07T16:19:00+08:00">2016-11-07</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2016-11-18 15:28:38" itemprop="dateModified" datetime="2016-11-18T15:28:38+08:00">2016-11-18</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2016/11/07/caffe学习（7）损失层、通用层/" class="leancloud_visitors" data-flag-title="caffe学习（7）损失层、通用层">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views: </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p><a href="http://caffe.berkeleyvision.org/tutorial/layers.html" target="_blank" rel="external">Caffe Layers</a><br><a href="http://www.cnblogs.com/denny402/p/5072746.html" target="_blank" rel="external">Caffe学习系列(5)：其它常用层及参数，denny402</a></p>
</blockquote>
<h2 id="损失层Loss-Layers"><a href="#损失层Loss-Layers" class="headerlink" title="损失层Loss Layers"></a>损失层Loss Layers</h2><hr>
<p>损失通过将输出与目标进行比较，并不断优化减小loss。</p>
<p><strong>Softmax（with loss）</strong></p>
<ul>
<li>层类型：SoftmaxWithLoss</li>
<li><p>示例：</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">	layer &#123;</div><div class="line">	  name: <span class="string">"loss"</span></div><div class="line">	  type: <span class="string">"SoftmaxWithLoss"</span></div><div class="line">	  bottom: <span class="string">"ip1"</span></div><div class="line">	  bottom: <span class="string">"label"</span></div><div class="line">	  top: <span class="string">"loss"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>在概念上等同于softmax layer+多项对数损失层（multinomial logistic loss layer），但提供了更稳定的梯度。softmax只是输出每一类的概率，并没有与label做比较。</p>
<p><strong>Sum-of-Squares / Euclidean</strong></p>
<ul>
<li>层类型：EuclideanLoss<br>这是比较传统的求偏差的方法，$\frac 1 {2N} \sum_{i=1}^N | x^1_i - x^2_i |_2^2$，直接计算欧氏距离。</li>
</ul>
<p><strong>Hinge / Margin</strong></p>
<ul>
<li>层类型：HingeLoss</li>
<li><p>参数(HingeLossParameter hinge_loss_param)：</p>
<ul>
<li>可选<ul>
<li>norm [default L1]:应该是正则化方法，目前只有L1、L2。</li>
</ul>
</li>
<li>输入： <ul>
<li>n <em> c </em> h * w Predictions预测值</li>
<li>n <em> 1 </em> 1 * 1 Labels标签</li>
</ul>
</li>
<li>输出：1 <em> 1 </em> 1 * 1 Computed Loss</li>
</ul>
</li>
<li><p>示例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># L1 Norm L1正则</span></div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"loss"</span></div><div class="line">  type: <span class="string">"HingeLoss"</span></div><div class="line">  bottom: <span class="string">"pred"</span></div><div class="line">  bottom: <span class="string">"label"</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment"># L2 Norm L2正则</span></div><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"loss"</span></div><div class="line">  type: <span class="string">"HingeLoss"</span></div><div class="line">  bottom: <span class="string">"pred"</span></div><div class="line">  bottom: <span class="string">"label"</span></div><div class="line">  top: <span class="string">"loss"</span></div><div class="line">  hinge_loss_param &#123;</div><div class="line">    norm: L2</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p><a href="https://en.wikipedia.org/wiki/Hinge_loss" target="_blank" rel="external">Hinge loss</a>主要用于SVM。</p>
<p><strong>Accuracy</strong></p>
<ul>
<li>层类型：Accuracy</li>
<li><p>示例</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">	  name: <span class="string">"accuracy"</span></div><div class="line">	  type: <span class="string">"Accuracy"</span></div><div class="line">	  bottom: <span class="string">"ip2"</span></div><div class="line">	  bottom: <span class="string">"label"</span></div><div class="line">	  top: <span class="string">"accuracy"</span></div><div class="line">	  include &#123;</div><div class="line">		    phase: TEST</div><div class="line">		  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>只有test阶段才有，因此需要加入include参数。它实际上不是损失并且没有后退步骤。</p>
<h2 id="通用层Common-Layers"><a href="#通用层Common-Layers" class="headerlink" title="通用层Common Layers"></a>通用层Common Layers</h2><hr>
<p><strong>Inner Product</strong></p>
<ul>
<li>层类型：InnerProduct</li>
<li>参数 (InnerProductParameter inner_product_param)：<ul>
<li>必须参数<ul>
<li>num_output (c_o):滤波器数量。</li>
</ul>
</li>
<li>推荐参数<ul>
<li>weight_filler [default type: ‘constant’ value: 0]：全职初始化方式、值。还可以选择”xavier”算法来进行初始化，也可以设置为”gaussian”。</li>
</ul>
</li>
<li>可选参数<ul>
<li>bias_filler [default type: ‘constant’ value: 0]：偏置初始化。</li>
<li>bias_term [default true]: 是否启用偏置项。</li>
</ul>
</li>
</ul>
</li>
<li>输入：n <em> c_i </em> h_i * w_i</li>
<li>输出：n <em> c_o </em> 1 * 1</li>
<li><p>示例：</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">	  name: <span class="string">"fc8"</span></div><div class="line">	  type: <span class="string">"InnerProduct"</span></div><div class="line">	  <span class="comment"># learning rate and decay multipliers for the weights</span></div><div class="line">	  param &#123; lr_mult: <span class="number">1</span> decay_mult: <span class="number">1</span> &#125;</div><div class="line">  <span class="comment"># learning rate and decay multipliers for the biases</span></div><div class="line">	  param &#123; lr_mult: <span class="number">2</span> decay_mult: <span class="number">0</span> &#125;</div><div class="line">	  inner_product_param &#123;</div><div class="line">		    num_output: <span class="number">1000</span></div><div class="line">		    weight_filler &#123;</div><div class="line">			      type: <span class="string">"gaussian"</span></div><div class="line">			      std: <span class="number">0.01</span></div><div class="line">			    &#125;</div><div class="line">		    bias_filler &#123;</div><div class="line">			      type: <span class="string">"constant"</span></div><div class="line">			      value: <span class="number">0</span></div><div class="line">			    &#125;</div><div class="line">		  &#125;</div><div class="line">	  bottom: <span class="string">"fc7"</span></div><div class="line">	  top: <span class="string">"fc8"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>Reshape</strong></p>
<ul>
<li>层类型：Reshape</li>
<li><p>参数 (ReshapeParameter reshape_param)：</p>
<ul>
<li>可选参数：<ul>
<li>shape</li>
</ul>
</li>
</ul>
</li>
<li><p>输入：单独的blob</p>
</li>
<li>输出：变形后的blob</li>
<li><p>示例：</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">	    name: <span class="string">"reshape"</span></div><div class="line">	    type: <span class="string">"Reshape"</span></div><div class="line">	    bottom: <span class="string">"input"</span></div><div class="line">	    top: <span class="string">"output"</span></div><div class="line">	    reshape_param &#123;</div><div class="line">		      shape &#123;</div><div class="line">		        dim: <span class="number">0</span>  <span class="comment"># copy the dimension from below</span></div><div class="line">		        dim: <span class="number">2</span></div><div class="line">		        dim: <span class="number">3</span></div><div class="line">		        dim: <span class="number">-1</span> <span class="comment"># infer it from the other dimensions</span></div><div class="line">		      &#125;</div><div class="line">	    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>这一操作不改变数据，只改变维度，也没有在过程中拷贝数据。输出的尺寸有shape参数的值规定，正数是对应的维度，除此外还有两个特殊值：</p>
<ul>
<li><strong>0</strong>表示复制底层对应的维度。bottom第一维度值为2，top第一维度也是2。</li>
<li><strong>-1</strong>表示从其他维度推断。为了保证数据总数不变，可以根据其他维数值计算。</li>
</ul>
<p>特别的，当时用参数：<code>reshape_param { shape { dim: 0 dim: -1 } }</code>时，reshape层相当于flatten层，将n <em> c </em> h <em> w的数据变为n </em> (c<em>h</em>w)。</p>
<p><strong>Concatenation</strong></p>
<ul>
<li>层类型： Concat</li>
<li>参数 (ConcatParameter concat_param)：<ul>
<li>可选参数<ul>
<li>axis [default 1]: 0表示沿着数量（n），1表示沿着通道（C）。</li>
</ul>
</li>
<li>输入：n_i <em> c_i </em> h * w 对于每个blob输入，i= 1 到 K。</li>
<li>输出：<ul>
<li>当 axis = 0: (n_1 + n_2 + … + n_K) <em> c_1 </em> h * w, 所有的c_i应该相同。</li>
<li>当 axis = 1: n_1 <em> (c_1 + c_2 + … + c_K) </em> h * w, 所有的n_i 应该相同。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>这个层把多个blob连接为一个blob。</p>
<hr>
<p>层的学习暂时到这里。。</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://joyfyan.github.io/2016/11/07/caffe学习（6）激活层/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yan Joy">
      <meta itemprop="description" content="Default~">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小一一的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/11/07/caffe学习（6）激活层/" itemprop="url">
                  caffe学习（6）激活层
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-11-07 11:22:00" itemprop="dateCreated datePublished" datetime="2016-11-07T11:22:00+08:00">2016-11-07</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2016-11-18 15:27:48" itemprop="dateModified" datetime="2016-11-18T15:27:48+08:00">2016-11-18</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2016/11/07/caffe学习（6）激活层/" class="leancloud_visitors" data-flag-title="caffe学习（6）激活层">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views: </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>激活（Activation）层又叫神经元（Neuron）层，最主要的是激活函数的设置。</p>
<blockquote>
<p><a href="http://caffe.berkeleyvision.org/tutorial/layers.html" target="_blank" rel="external">Activation / Neuron Layers</a><br><a href="http://www.cnblogs.com/louyihang-loves-baiyan/p/5200850.html" target="_blank" rel="external">Caffe源码解析6：Neuron_Layer，楼燚航的blog</a></p>
</blockquote>
<hr>
<p>一般来说，这一层是元素级的运算符，从底部blob作为输入并产生一个相同大小的顶部blob：</p>
<ul>
<li>输入：n <em> c </em> h * w</li>
<li>输出：n <em> c </em> h * w</li>
</ul>
<p><strong>ReLU / Rectified-Linear and Leaky-ReLU</strong></p>
<ul>
<li>层类型：ReLU</li>
<li>参数(ReLUParameter relu_param)：<ul>
<li>可选参数<ul>
<li>negative_slope [default 0]: 用来指定负斜率部分的因子$\nu$。完整的函数表达式为：$y = \max(0, x) + \nu \min(0, x)$。反向传播的公式为<br>$$\frac{\partial E}{\partial x} = \left{<br>\begin{array}{lr}<br>\nu \frac{\partial E}{\partial y} &amp; \mathrm{if} \; x \le 0 \<br>\frac{\partial E}{\partial y} &amp; \mathrm{if} \; x &gt; 0<br>\end{array} \right.<br>$$</li>
</ul>
</li>
</ul>
</li>
<li><p>示例（./models/bvlc_reference_caffenet/train_val.prototxt）：</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: <span class="string">"relu1"</span></div><div class="line">  type: <span class="string">"ReLU"</span></div><div class="line">  bottom: <span class="string">"conv1"</span></div><div class="line">  top: <span class="string">"conv1"</span></div><div class="line">&#125;</div><div class="line">	```  </div><div class="line">	支持<span class="keyword">in</span>-place计算，bottom输入和top输出可以相同避免内存消耗。</div><div class="line">	</div><div class="line">**Sigmoid**</div><div class="line"></div><div class="line"> - 层类型：Sigmoid</div><div class="line"> - 示例( ./models/bvlc_reference_caffenet/train_val.prototxt)：</div><div class="line"></div><div class="line">	```python</div><div class="line">layer &#123;</div><div class="line">	  name: <span class="string">"relu1"</span></div><div class="line">	  type: <span class="string">"ReLU"</span></div><div class="line">	  bottom: <span class="string">"conv1"</span></div><div class="line">	  top: <span class="string">"conv1"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>激活函数表达式为$y = (1 + \exp(-x))^{-1}$，由于收敛速度问题现在用的不多了。</p>
<p><strong>TanH、AbsVal、BNLL</strong></p>
<ul>
<li>层类型：TanH、AbsVal、BNLL</li>
<li><p>示例：</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">	layer &#123;</div><div class="line">	  name: <span class="string">"layer"</span></div><div class="line">	  bottom: <span class="string">"in"</span></div><div class="line">	  top: <span class="string">"out"</span></div><div class="line">	  type: <span class="string">"TanH"</span><span class="comment">#"AbsVal"、“BNLL”官网上BNLL没有加双引号，应该是有误</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>分别是双曲正切函数、绝对值、binomial normal log likelihood（$f(x)=log(1 + e^x)$）的简称。</p>
<p><strong>Power</strong></p>
<ul>
<li>层类型：Power</li>
<li>参数 (PowerParameter power_param)：<ul>
<li>可选<ul>
<li>power [default 1]</li>
<li>scale [default 1]</li>
<li>shift [default 0]</li>
</ul>
</li>
</ul>
</li>
<li><p>示例：</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">	layer &#123;</div><div class="line">	  name: <span class="string">"layer"</span></div><div class="line">	  bottom: <span class="string">"in"</span></div><div class="line">	  top: <span class="string">"out"</span></div><div class="line">	  type: <span class="string">"Power"</span></div><div class="line">	  power_param &#123;</div><div class="line">		    power: <span class="number">2</span></div><div class="line">		    scale: <span class="number">1</span></div><div class="line">		    shift: <span class="number">0</span></div><div class="line">	  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>幂运算函数为$f(x)= (shift + scale * x) ^ p$。</p>
<hr>
<p>Caffe中的激活层还有很多，也有一些是加速的层。比如DropoutLayer现在是非常常用的一种网络层，只用在训练阶段，一般用在网络的全连接层中，可以减少网络的过拟合问题。<br>具体的使用再具体看./src/caffe/layers/下的文件吧。</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://joyfyan.github.io/2016/11/06/caffe学习（5）视觉层/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yan Joy">
      <meta itemprop="description" content="Default~">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小一一的小站">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/11/06/caffe学习（5）视觉层/" itemprop="url">
                  caffe学习（5）视觉层
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2016-11-06 22:52:00" itemprop="dateCreated datePublished" datetime="2016-11-06T22:52:00+08:00">2016-11-06</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2016-11-18 15:34:56" itemprop="dateModified" datetime="2016-11-18T15:34:56+08:00">2016-11-18</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2016/11/06/caffe学习（5）视觉层/" class="leancloud_visitors" data-flag-title="caffe学习（5）视觉层">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views: </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>上一篇是数据层，这一篇是视觉层（Vision Layers）。参考官网和网友博客。</p>
<blockquote>
<p><a href="http://caffe.berkeleyvision.org/tutorial/layers.html" target="_blank" rel="external">Vision Layers</a><br><a href="http://www.cnblogs.com/denny402/p/5071126.html" target="_blank" rel="external">Caffe学习系列(3)：视觉层（Vision Layers)及参数，denny402</a><br><a href="http://www.cnblogs.com/louyihang-loves-baiyan/p/5154337.html" target="_blank" rel="external">Caffe源码解析5：Conv_Layer，楼燚航的blog</a></p>
</blockquote>
<hr>
<p>视觉层通常将图像作为输入，产生其他图像作为输出。图像输入可以是灰度图（通道C=1），RGB图（通道C=3）。同样图像也具有二维的空间结构，其高度$h&gt;1$宽度$w&gt;1$。大多数视觉层通过对输入区域应用特定操作产生输出的相应区域，这里就有点像传统的数字图像处理的工作了。相比之下其他层常常忽略输入的空间结构，视其为具有$chw$维度的大向量。</p>
<h2 id="卷积层Convolution"><a href="#卷积层Convolution" class="headerlink" title="卷积层Convolution"></a>卷积层Convolution</h2><hr>
<ul>
<li>层类型：Convolution</li>
<li>CPU实现：./src/caffe/layers/convolution_layer.cpp</li>
<li>CUDA GPU实现： ./src/caffe/layers/convolution_layer.cu</li>
<li><p>参数 (ConvolutionParameter convolution_param)：</p>
<ul>
<li>必须参数<ul>
<li>num_output (c_o):卷积核（filter）的个数。</li>
<li>kernel_size (or kernel_h and kernel_w): 卷积核大小，非方阵用_h _w。</li>
</ul>
</li>
<li>推荐参数<ul>
<li>weight_filler [default type: ‘constant’ value: 0]：卷积核的初始化，默认为全0，可以用”xavier”算法来进行初始化，也可以设置为”gaussian”。</li>
</ul>
</li>
<li><p>可选参数</p>
<ul>
<li>bias_term [default true]:是否开启偏置项，默认为true, 开启。</li>
<li>pad (or pad_h and pad_w) [default 0]: 填零操作，默认为0，不填零。是对原图进行填零，使卷积核在图像边缘能够进行卷积操作，运算后和原图的尺寸相同。扩充的时候是左右、上下对称的，比如卷积核的大小为5*5，那么pad设置为2，则四个边缘都扩充2个像素，即宽度和高度都扩充了4个像素。</li>
<li>stride (or stride_h and stride_w) [default 1]: 卷积核的移动步长，默认为1。</li>
<li><p>group (g) [default 1]: 分组，默认为1组。如果大于1，我们限制卷积的连接操作在一个子集内。如果我们根据图像的通道来分组，那么第i个输出分组只能与第i个输入分组进行连接。groups是代表filter 组的个数。引入gruop主要是为了选择性的连接卷基层的输入端和输出端的channels，否则参数会太多。</p>
<blockquote>
<p>It was there to implement the grouped convolution in Alex Krizhevsky’s paper: when group=2, the first half of the filters are only connected to the first half of the input channels, and the second half only connected to the second half.</p>
</blockquote>
<p> 当group=2时，前半部分filter与输入的前半部分通道连接，后半部分filter与后半部分输入通道连接。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>输入：n <em> c_i </em> h_i * w_i</p>
</li>
<li>输出：n <em> c_o </em> h_o <em> w_o, where h_o = (h_i + 2 </em> pad_h - kernel_h) / stride_h + 1 and w_o likewise。</li>
<li><p>示例 (./models/bvlc_reference_caffenet/train_val.prototxt)</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">	  name: <span class="string">"conv1"</span></div><div class="line">	  type: <span class="string">"Convolution"</span></div><div class="line">	  bottom: <span class="string">"data"</span></div><div class="line">	  top: <span class="string">"conv1"</span></div><div class="line">	  <span class="comment"># learning rate and decay multipliers for the </span></div><div class="line">	  <span class="comment"># filters</span></div><div class="line">	  param &#123; lr_mult: <span class="number">1</span> decay_mult: <span class="number">1</span> &#125;</div><div class="line">	  <span class="comment"># learning rate and decay multipliers for the biases</span></div><div class="line">	  param &#123; lr_mult: <span class="number">2</span> decay_mult: <span class="number">0</span> &#125;</div><div class="line">	  convolution_param &#123;</div><div class="line">		    num_output: <span class="number">96</span>     </div><div class="line">		    <span class="comment"># learn 96 filters</span></div><div class="line">		    kernel_size: <span class="number">11</span>    </div><div class="line">		    <span class="comment"># each filter is 11x11</span></div><div class="line">			stride: <span class="number">4</span>      </div><div class="line">			<span class="comment"># step 4 pixels between each filter </span></div><div class="line">			<span class="comment"># application</span></div><div class="line">		    weight_filler &#123;</div><div class="line">			    type: <span class="string">"gaussian"</span> </div><div class="line">			    <span class="comment"># initialize the filters from a Gaussian</span></div><div class="line">			    std: <span class="number">0.01</span>        </div><div class="line">			    <span class="comment"># distribution with stdev 0.01 (default </span></div><div class="line">			    <span class="comment"># mean: 0)</span></div><div class="line">		    &#125;</div><div class="line">		    bias_filler &#123;</div><div class="line">			    type: <span class="string">"constant"</span> </div><div class="line">			    <span class="comment"># initialize the biases to zero (0)</span></div><div class="line">			    value: <span class="number">0</span></div><div class="line">			&#125;</div><div class="line">		 &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>卷积层将输入图像与一组可学习的滤波器进行卷积，每个在输出图像中产生一个特征图。</p>
</li>
</ul>
<h2 id="池化层Pooling"><a href="#池化层Pooling" class="headerlink" title="池化层Pooling"></a>池化层Pooling</h2><hr>
<p>Pooling 层一般在网络中是跟在Conv卷积层之后，做采样操作，其实是为了进一步缩小feature map，同时也能增大神经元的视野。</p>
<ul>
<li>层类型：Pooling</li>
<li>CPU实现：./src/caffe/layers/pooling_layer.cpp</li>
<li>CUDA GPU实现：./src/caffe/layers/pooling_layer.cu</li>
<li>参数(PoolingParameter pooling_param)：<ul>
<li>必须<ul>
<li>kernel_size (or kernel_h and kernel_w)：池化核大小。</li>
</ul>
</li>
<li>可选参数<ul>
<li>pool [default MAX]: 池化方法，默认为MAX，还有 AVE, or STOCHASTIC。</li>
<li>pad (or pad_h and pad_w) [default 0]:填零。</li>
<li>stride (or stride_h and stride_w) [default 1]:步长。</li>
</ul>
</li>
<li>输入：n <em> c </em> h_i * w_i</li>
<li>输出：n <em> c </em> h_o * w_o，h_o and w_o 与卷积层计算方法相同。</li>
</ul>
</li>
<li><p>示例 ( ./models/bvlc_reference_caffenet/train_val.prototxt)</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">	  name: <span class="string">"pool1"</span></div><div class="line">	  type: <span class="string">"Pooling"</span></div><div class="line">	  bottom: <span class="string">"conv1"</span></div><div class="line">	  top: <span class="string">"pool1"</span></div><div class="line">	  pooling_param &#123;</div><div class="line">		    pool: MAX</div><div class="line">		    kernel_size: <span class="number">3</span> <span class="comment"># pool over a 3x3 region</span></div><div class="line">		    stride: <span class="number">2</span>      <span class="comment"># step two pixels (in the </span></div><div class="line">						   <span class="comment"># bottom blob) between pooling </span></div><div class="line">						   <span class="comment"># regions</span></div><div class="line">		  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="局部响应归一化层RNL"><a href="#局部响应归一化层RNL" class="headerlink" title="局部响应归一化层RNL"></a>局部响应归一化层RNL</h2><hr>
<p>局部响应归一化层通过对局部输入区域进行归一化来执行一种“横向抑制”。具体作用感觉和特征缩放有点像，使梯度下降在所有方向上具有相同的曲率。而RNL这种方法的计算相比对每个神经元输入归一化要简单。</p>
<ul>
<li>层类型：LRN</li>
<li>CPU实现： ./src/caffe/layers/lrn_layer.cpp</li>
<li>CUDA GPU实现：./src/caffe/layers/lrn_layer.cu</li>
<li>参数 (LRNParameter lrn_param)：<ul>
<li>可选参数<ul>
<li>local_size [default 5]:需要求和的通道数数目（对于跨通道LRN），或者是方形区域求和的变长（对于通道内LRN）。</li>
<li>alpha [default 1]: 比例参数。</li>
<li>beta [default 5]: 指数参数。</li>
<li>norm_region [default ACROSS_CHANNELS]:ACROSS_CHANNELS表示在相邻的通道间求和归一化，但没有空间延伸，即大小为local_size x 1 x 1；WITHIN_CHANNEL表示在一个通道内部特定的区域内进行求和归一化，其大小为：1 x local_size x local_size。每个输入值被除以$(1 + (\alpha/n) \sum_i x_i^2)^\beta$，$n$是每个局部区域的大小。</li>
</ul>
</li>
</ul>
</li>
<li><p>示例：</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">layers &#123;</div><div class="line">	  name: <span class="string">"norm1"</span></div><div class="line">	  type: LRN</div><div class="line">	  bottom: <span class="string">"pool1"</span></div><div class="line">	  top: <span class="string">"norm1"</span></div><div class="line">	  lrn_param &#123;</div><div class="line">		    local_size: <span class="number">5</span></div><div class="line">		    alpha: <span class="number">0.0001</span></div><div class="line">		    beta: <span class="number">0.75</span></div><div class="line">		  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="Im2col"><a href="#Im2col" class="headerlink" title="Im2col"></a>Im2col</h2><hr>
<p>Caffe中卷积操作需要先对数据进行im2col，再进行内积运算，如下图所示：<br><img src="http://images2015.cnblogs.com/blog/140867/201512/140867-20151224103937640-1245969956.jpg" alt="卷积计算"></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/9/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/11/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Yan Joy" />
            
              <p class="site-author-name" itemprop="name">Yan Joy</p>
              <p class="site-description motion-element" itemprop="description">Default~</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">98</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">11</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">58</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="http://weibo.com/yanjoy" target="_blank" title="Weibo"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="http://blog.csdn.net/yan_joy" target="_blank" title="CSDN"><i class="fa fa-fw fa-linux"></i>CSDN</a>
                  
                </span>
              
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                FRIENDS
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.xieqiang.site/" title="Johnny" target="_blank">Johnny</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://judasdie.github.io/" title="ZP Zhang" target="_blank">ZP Zhang</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://pages.coding.me/" title="Hosted by Coding Pages" target="_blank">Hosted by Coding Pages</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2016 – <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Joy</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> v3.2.2</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Pisces</a> v6.3.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
      <div>
        <!-- Go to www.addthis.com/dashboard to customize your tools -->
<div class="addthis_inline_share_toolbox">
  <script type = "text/javascript" src = "//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5b692d42870e12d9" async = "async" ></script>
</div>

      </div>
    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.3.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("CETsF97cGhnDDoeuypbWtlvs-gzGzoHsz", "owWjRRJ2oBD7Dekc8l1RRctK");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            
            counter.save(null, {
              success: function(counter) {
                
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(counter.get('time'));
                
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            
              var newcounter = new Counter();
              /* Set ACL */
              var acl = new AV.ACL();
              acl.setPublicReadAccess(true);
              acl.setPublicWriteAccess(true);
              newcounter.setACL(acl);
              /* End Set ACL */
              newcounter.set("title", title);
              newcounter.set("url", url);
              newcounter.set("time", 1);
              newcounter.save(null, {
                success: function(newcounter) {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
                },
                error: function(newcounter, error) {
                  console.log('Failed to create');
                }
              });
            
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  

</body>
</html>
